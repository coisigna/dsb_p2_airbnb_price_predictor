{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59156d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "import folium\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from collections import Counter\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab23190",
   "metadata": {},
   "outputs": [],
   "source": [
    "class airbnb_city:\n",
    "    \n",
    "    def __init__(self, csv):\n",
    "        \n",
    "        self.csv = csv\n",
    "                \n",
    "        self.df_city = pd.read_csv(self.csv)\n",
    "        \n",
    "        print(\"Instance created!\")\n",
    "        \n",
    "    def clean_columns(self):\n",
    "        \n",
    "        # Take only the relevant columns in the dataframe\n",
    "        \n",
    "        l_relevant_columns = [\"host_is_superhost\",\"neighbourhood_cleansed\",\"neighbourhood_group_cleansed\",\"property_type\",\"room_type\",\"accommodates\",\"bathrooms_text\",\"beds\",\"price\",\"minimum_nights\",\"maximum_nights\",\"availability_30\",\"availability_365\",\"number_of_reviews\",\"instant_bookable\", \"amenities\", \"host_verifications\"]\n",
    "\n",
    "        self.df_city = self.df_city[l_relevant_columns]\n",
    "        \n",
    "        self.df_city[\"bathrooms_text\"].replace(np.nan, \"?\", inplace = True)\n",
    "        \n",
    "        # Get numbers out of bathroom_text columns\n",
    "        \n",
    "        l_nums = [re.findall(r'\\d+',i) for i in self.df_city[\"bathrooms_text\"].values]\n",
    "\n",
    "        l_nums_completed = []\n",
    "\n",
    "        for i in l_nums:\n",
    "\n",
    "            if len(i) > 1:\n",
    "\n",
    "                l_nums_completed.append('.'.join(i))\n",
    "\n",
    "            elif len(i) == 0:\n",
    "\n",
    "                l_nums_completed.append('0')\n",
    "\n",
    "            else:\n",
    "\n",
    "                l_nums_completed.append(i[0])\n",
    "\n",
    "        # Separate categories from bathroom_text\n",
    "        \n",
    "        l_category = []\n",
    "\n",
    "        for i in self.df_city[\"bathrooms_text\"].values:\n",
    "\n",
    "            if \"shared\" in i:\n",
    "\n",
    "                l_category.append(\"Shared\")\n",
    "\n",
    "            elif \"private\" in i:\n",
    "\n",
    "                l_category.append(\"Private\")\n",
    "\n",
    "            else:\n",
    "\n",
    "                l_category.append(\"Unknown\")\n",
    "                \n",
    "        # Create two different columns replacing bathroom_text\n",
    "        \n",
    "        self.df_city.drop(\"bathrooms_text\", axis = 1, inplace = True)\n",
    "                \n",
    "        self.df_city[\"num_of_baths\"] = l_nums_completed\n",
    "        \n",
    "        self.df_city[\"bath_category\"] = l_category\n",
    "        \n",
    "        self.df_city[\"num_of_baths\"] = self.df_city[\"num_of_baths\"].astype(\"float64\")\n",
    "\n",
    "        # Column[\"prices\"]\n",
    "        \n",
    "        self.df_city[\"price\"]  = self.df_city[\"price\"] .apply(lambda x: float(x.strip(\"$\").replace(',', '')) if pd.notnull(x) else x)\n",
    "        \n",
    "        self.df_city[\"amenities\"] = [len(i) for i in self.df_city[\"amenities\"]]\n",
    "\n",
    "        self.df_city[\"host_verifications\"] = [len(i) for i in self.df_city[\"host_verifications\"]]\n",
    "        \n",
    "        \n",
    "        print(\"Dataframe sucessfully created!\")\n",
    "    \n",
    "    def label_encoding(self):\n",
    "        \n",
    "        self.df_city.dropna(inplace=True)\n",
    "        \n",
    "        # Encoding columns with dummies function\n",
    "        \n",
    "        def dummies(data, column):\n",
    "            return pd.get_dummies(data = data[column], drop_first=True)\n",
    "        \n",
    "        self.df_city[\"host_is_superhost\"] = dummies(self.df_city, \"host_is_superhost\")\n",
    "        self.df_city[\"instant_bookable\"] = dummies(self.df_city, \"instant_bookable\")\n",
    "        \n",
    "        df_room_type = dummies(self.df_city, \"room_type\")\n",
    "        df_bath_category = dummies(self.df_city, \"bath_category\")\n",
    "        df_bath_category = df_bath_category.rename(columns={'Shared': 'shared_bath', 'Unknown': 'unknoun_bath'})\n",
    "        \n",
    "        self.df_city = pd.concat([self.df_city, df_bath_category], axis = 1)\n",
    "\n",
    "        self.df_city = pd.concat([self.df_city, df_room_type], axis = 1)\n",
    "\n",
    "        self.df_city.drop(\"room_type\", axis = 1, inplace = True)\n",
    "\n",
    "        self.df_city.drop(\"bath_category\", axis = 1, inplace = True)\n",
    "        \n",
    "        # Encoding categorical columns with labelEncoding function\n",
    "        \n",
    "        l_columns_to_labelEncode = [\"neighbourhood_cleansed\", \"property_type\", \"neighbourhood_group_cleansed\"]\n",
    "        l_columns_encoded = list()\n",
    "\n",
    "        for i in l_columns_to_labelEncode:\n",
    "\n",
    "            # Inicializing object LabelEncoder()\n",
    "            o_labelEncoding = LabelEncoder()\n",
    "\n",
    "            # Training it with the column data\n",
    "            o_labelEncoding.fit(self.df_city[i].values)\n",
    "\n",
    "            # Transform the column\n",
    "            l_columns_encoded.append(o_labelEncoding.transform(self.df_city[i].values))\n",
    "\n",
    "        self.df_city[\"neighbourhood_cleansed\"] = l_columns_encoded[0]\n",
    "        self.df_city[\"property_type\"] = l_columns_encoded[1]\n",
    "        self.df_city[\"neighbourhood_group_cleansed\"] = l_columns_encoded[2]\n",
    "        \n",
    "        print(\"Dataframe sucessfully encoded!\")\n",
    "\n",
    "        \n",
    "    def return_df(self):\n",
    "    \n",
    "        return self.df_city\n",
    "    \n",
    "    def display_df(self):\n",
    "    \n",
    "        display(self.df_city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bcb1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "madrid = airbnb_city(\"C:\\\\Users\\\\ignci\\\\OneDrive\\\\Escritorio\\\\Curso\\\\Coisigna\\\\dsb-p2-ml\\\\ipynbs\\datasets\\\\Madrid air bnb\\\\madrid.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79e5f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = madrid.return_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30788c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735fc0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"price\"] = df[\"price\"].apply(lambda x: float(x.strip(\"$\").replace(',', '')) if pd.notnull(x) else x).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3019ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"price\"]<700]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0b5de0",
   "metadata": {},
   "source": [
    "## Cleaning property_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a49629",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "dict_property_types = dict(Counter(df[\"property_type\"]))\n",
    "\n",
    "dict_property_types[list(dict_property_types.keys())[0]]\n",
    "\n",
    "list_others = []\n",
    "for i in dict_property_types.keys():\n",
    "    \n",
    "    if dict_property_types[i] < 300:\n",
    "        \n",
    "        list_others.append(i)\n",
    "        \n",
    "for i in list_others:\n",
    "    \n",
    "    df[\"property_type\"].replace(i,\"Other\", inplace = True)\n",
    "\n",
    "df[\"property_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31062422",
   "metadata": {},
   "source": [
    "### Encoding property_type with the mean values of the price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556396b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.groupby(\"property_type\").mean().price\n",
    "\n",
    "# for i, j in zip(df.groupby(\"property_type\").mean().price.index, df.groupby(\"property_type\").mean().price.values):\n",
    "#     df[\"property_type\"].replace(i, j, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf70c50",
   "metadata": {},
   "source": [
    "### Encoding property_type with get dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc5e8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_property_type = dummies(df, \"property_type\")\n",
    "\n",
    "# df = pd.concat([df, df_property_type], axis = 1)\n",
    "\n",
    "# df.drop(\"property_type\", axis = 1, inplace = True)\n",
    "\n",
    "# df_property_type.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b79303f",
   "metadata": {},
   "source": [
    "### Encoding property_type with label encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9227cdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializing object LabelEncoder()\n",
    "o_labelEncoding = LabelEncoder()\n",
    "\n",
    "# Training it with the column data\n",
    "o_labelEncoding.fit(df[\"property_type\"].values)\n",
    "\n",
    "# Transform the column\n",
    "property_type = o_labelEncoding.transform(df[\"property_type\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479094a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"property_type\"] = property_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82093f01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30c9c9b2",
   "metadata": {},
   "source": [
    "# neighbourhood_group_cleansed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c98d79",
   "metadata": {},
   "source": [
    "## Encoding with label encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22f61c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializing object LabelEncoder()\n",
    "o_labelEncoding = LabelEncoder()\n",
    "\n",
    "# Training it with the column data\n",
    "o_labelEncoding.fit(df[\"neighbourhood_group_cleansed\"].values)\n",
    "\n",
    "# Transform the column\n",
    "neighbourhood_group_cleansed = o_labelEncoding.transform(df[\"neighbourhood_group_cleansed\"].values)\n",
    "\n",
    "df[\"neighbourhood_group_cleansed\"] = neighbourhood_group_cleansed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bc58b8",
   "metadata": {},
   "source": [
    "## Encoding with C.P."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3253b585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_neighbourhood_group_cleansed_cp = {\"Centro\": 28013, \"Arganzuela\": 28045, \"Retiro\": 28007, \"Salamanca\": 28001, \"Chamartín\": 28002, \"Tetuán\": 28020, \"Chamberí\": 28010, \"Fuencarral - El Pardo\": 28029, \"Moncloa - Aravaca\": 28008, \"Latina\": 28044, \"Carabanchel\": 28025, \"Usera\": 28026, \"Puente de Vallecas\": 28038, \"Moratalaz\": 28030, \"Ciudad Lineal\": 28037, \"Hortaleza\": 28043, \"Villaverde\": 28021, \"Villa de Vallecas\": 28031, \"Vicálvaro\": 28032, \"San Blas - Canillejas\": 28022, \"Barajas\": 28042}\n",
    "\n",
    "# for i, j in d_neighbourhood_group_cleansed_cp.items():\n",
    "#     df[\"neighbourhood_group_cleansed\"].replace(i, j, inplace=True)\n",
    "\n",
    "# df[\"neighbourhood_group_cleansed\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd557b9",
   "metadata": {},
   "source": [
    "## Cleaning room_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d22bca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummies(data, column):\n",
    "    return pd.get_dummies(data = data[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f481f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_room_type = dummies(df, \"room_type\")\n",
    "\n",
    "df = pd.concat([df, df_room_type], axis = 1)\n",
    "\n",
    "df.drop(\"room_type\", axis = 1, inplace = True)\n",
    "\n",
    "df_room_type.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f4899d",
   "metadata": {},
   "source": [
    "## Cleaning amenities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5042884f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "l_amenities_cleaned = list()\n",
    "for i in df[\"amenities\"]:\n",
    "    \n",
    "    l_amenities_cleaned.append(json.loads(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26040a3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l_amenities_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9114414e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More relevant amenities, to see why check EDA _2_from_bedrooms.ipynb\n",
    "\n",
    "\n",
    "l_amenities_valuables = ['Long term stays allowed','Cooking basics','Dishes and silverware','Essentials','Coffee maker','Hair dryer','Microwave','Refrigerator','Heating','Air conditioning']\n",
    "                         \n",
    "                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fac7588",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_amenities_valuables = pd.DataFrame()\n",
    "\n",
    "for j in l_amenities_valuables:\n",
    "    \n",
    "    df_amenities_valuables[j] = [1 if j in i else 0 for i in l_amenities_cleaned]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e30f704",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_amenities_valuables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bbb736",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_amenities_valuables.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992b764d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, df_amenities_valuables], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a575fb2a",
   "metadata": {},
   "source": [
    "# Test 1: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c66268d",
   "metadata": {},
   "source": [
    "## R**2 = 0.43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c219a291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_columns_chosen = df[[\"host_id\", \"neighbourhood_group_cleansed\", \"latitude\", \"longitude\", \"Hotel room\", \"Private room\",\"Shared room\"  ,\"accommodates\", \"price\",\"minimum_nights\",\"availability_365\",\"number_of_reviews\",\"calculated_host_listings_count\", \"reviews_per_month\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb20664",
   "metadata": {},
   "source": [
    "# Test 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10803e41",
   "metadata": {},
   "source": [
    "## R**2 = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e08d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_columns_chosen = df[[\"neighbourhood_group_cleansed\",\"accommodates\", \"price\",\"minimum_nights\",\"availability_365\",\"number_of_reviews\",\"calculated_host_listings_count\", \"reviews_per_month\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07dd62c7",
   "metadata": {},
   "source": [
    "# Test: Adding property_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e12db0e",
   "metadata": {},
   "source": [
    "## Test 3.1: R**2 = 0.30 (Encoding property_type with the mean values of the price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74c9d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_columns_chosen = df[[\"neighbourhood_group_cleansed\",\"accommodates\", \"price\", \"property_type\", \"minimum_nights\",\"availability_365\",\"number_of_reviews\",\"calculated_host_listings_count\", \"reviews_per_month\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae217d17",
   "metadata": {},
   "source": [
    "## Test 3.2: R**2 = 0.26 (Encoding property_type with get dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91de2fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # df_columns_chosen = df[[\"neighbourhood_group_cleansed\",\"accommodates\", \"price\", 'Entire apartment', 'Entire condominium', 'Entire loft', 'Other',\n",
    "#                          'Private room in apartment', 'Private room in condominium',\n",
    "#                                'Private room in house', \"minimum_nights\",\"availability_365\",\"number_of_reviews\",\"calculated_host_listings_count\", \"reviews_per_month\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2245df8",
   "metadata": {},
   "source": [
    "##  Test 3.3: R**2 = 0.30 (Encoding property_type with label encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e7e47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_columns_chosen = df[[\"neighbourhood_group_cleansed\",\"accommodates\", \"price\", \"property_type\", \"minimum_nights\",\"availability_365\",\"number_of_reviews\",\"calculated_host_listings_count\", \"reviews_per_month\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd9590b",
   "metadata": {},
   "source": [
    "### It does not seem to be relevant to encode property_type either with label encoding or with the mean values of the price. It gets worst results to do it with get dummies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fd22f1",
   "metadata": {},
   "source": [
    "# Test 4: Adding room_type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6e6d20",
   "metadata": {},
   "source": [
    "## R**2 = 0.29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2227ffcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_columns_chosen = df[[\"neighbourhood_group_cleansed\",\"accommodates\", \"price\", \"property_type\",'Entire home/apt', 'Hotel room', 'Private room', 'Shared room', \"minimum_nights\",\"availability_365\",\"number_of_reviews\",\"calculated_host_listings_count\", \"reviews_per_month\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3723f40e",
   "metadata": {},
   "source": [
    "### It does not seem to improve with room_type therefor it will be discarded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51693599",
   "metadata": {},
   "source": [
    "# Test 5: subtracting calculated_host_listings_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179b6e07",
   "metadata": {},
   "source": [
    "## R**2 = 0.22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f08a220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_columns_chosen = df[[\"neighbourhood_group_cleansed\",\"accommodates\", \"price\", \"property_type\", \"minimum_nights\",\"availability_365\",\"number_of_reviews\", \"reviews_per_month\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccbf8d7",
   "metadata": {},
   "source": [
    "### It seem to get worst therefore we add it back"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6162fe",
   "metadata": {},
   "source": [
    "# Test 5: Diferences between encoding with label encode or CP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9647dbf9",
   "metadata": {},
   "source": [
    "## Test 5.1: With C.P. encode - R**\"2 = 0.24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cda8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_columns_chosen = df[[\"neighbourhood_group_cleansed\",\"accommodates\", \"price\", \"property_type\", \"minimum_nights\",\"availability_365\",\"number_of_reviews\",\"calculated_host_listings_count\", \"reviews_per_month\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e9f6f3",
   "metadata": {},
   "source": [
    "## Test 5.2: With label encoder - R**\"2 = 0.27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129d01cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_columns_chosen = df[[\"neighbourhood_group_cleansed\",\"accommodates\", \"price\", \"property_type\", \"minimum_nights\",\"availability_365\",\"number_of_reviews\",\"calculated_host_listings_count\", \"reviews_per_month\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd00c4c4",
   "metadata": {},
   "source": [
    "# Test 6: Adding amenities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b932001",
   "metadata": {},
   "source": [
    "## Test 6.1: Addin amenities(Kitchen, TV, Pool, Wifi, Bathtub) -  R**2 = 0.28 Improves just a little"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a108e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_columns_chosen = df[['Elevator', 'Kitchen', 'Pool', 'Wifi', 'Bathtub',\"neighbourhood_group_cleansed\",\"accommodates\", \"price\", \"property_type\", \"minimum_nights\",\"availability_365\",\"number_of_reviews\",\"calculated_host_listings_count\", \"reviews_per_month\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b4f1d6",
   "metadata": {},
   "source": [
    "## Test 6.2: Addin the 10 amenities more relevant followin the EDA - R**2 = 0.29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d8274d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_columns_chosen = df[['Long term stays allowed', 'Cooking basics', 'Dishes and silverware','Essentials', 'Coffee maker', 'Hair dryer', 'Microwave', 'Refrigerator','Heating', 'Air conditioning',\"neighbourhood_group_cleansed\",\"accommodates\", \"price\", \"property_type\", \"minimum_nights\",\"availability_365\",\"number_of_reviews\",\"calculated_host_listings_count\", \"reviews_per_month\"]]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b1657e",
   "metadata": {},
   "source": [
    "# Test 7: Linear regresion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde29f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_columns_chosen = df[[\"price\", \"reviews_per_month\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5715cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f765d988",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2062cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f360c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a8653c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_columns_chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4ee45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_columns_chosen = df_columns_chosen.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf169433",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_columns_chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a75bcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_columns_chosen.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d69a2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b817f7eb",
   "metadata": {},
   "source": [
    "# Getting rid of outliers using quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6013d7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"price\",\"reviews_per_month\"]\n",
    "\n",
    "for col in cols:\n",
    "    upper_bound = df_columns_chosen[col].quantile(0.95)\n",
    "    lower_bound = df_columns_chosen[col].quantile(0.05)\n",
    "    listings = df_columns_chosen[df_columns_chosen[col] < upper_bound]\n",
    "    listings = df_columns_chosen[df_columns_chosen[col] > lower_bound]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6ae50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot before transformation\n",
    "stats.probplot(df_columns_chosen[\"price\"], plot=plt)\n",
    "\n",
    "# Power Transformer\n",
    "numeric_cols = list(df_columns_chosen._get_numeric_data().columns)\n",
    "pt = PowerTransformer(method=\"yeo-johnson\")\n",
    "df_columns_chosen[numeric_cols] = pt.fit_transform(df_columns_chosen[numeric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4384aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After transformation\n",
    "stats.probplot(df_columns_chosen[\"price\"], plot=plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d78cf5c",
   "metadata": {},
   "source": [
    "# Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f790b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in df_columns_chosen.columns:\n",
    "    \n",
    "    print(i)\n",
    "    sns.kdeplot(df_columns_chosen[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c5512c",
   "metadata": {},
   "source": [
    "## Dividing x & y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1dd741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df_columns_chosen.drop(\"price\", axis = 1)\n",
    "# y = df_columns_chosen[[\"price\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8e7cf0",
   "metadata": {},
   "source": [
    "## Scaling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65878cc8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# scaler_x = StandardScaler()\n",
    "# scaler_x.fit(X)\n",
    "# X = scaler_x.transform(X)\n",
    "\n",
    "\n",
    "# scaler_y = StandardScaler()\n",
    "# scaler_y.fit(y)\n",
    "# y = scaler_y.transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88aa1125",
   "metadata": {},
   "source": [
    "# Feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1be5eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_class = df_columns_chosen[\"price\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c46bf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_columns_chosen.drop(\"price\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff3a4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(df_columns_chosen)\n",
    "y = np.asarray(df_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f642470",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed046796",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "# Build a forest and compute the feature importances\n",
    "forest = ExtraTreesRegressor(n_estimators = 250,\n",
    "                              random_state = 0)\n",
    "\n",
    "forest.fit(X, y)\n",
    "\n",
    "importances = forest.feature_importances_\n",
    "\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_], axis = 0)\n",
    "\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %d (%f): %s\" % (f + 1, indices[f], importances[indices[f]], df_columns_chosen.columns[f]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "\n",
    "plt.title(\"Feature importances\")\n",
    "\n",
    "plt.bar(range(X.shape[1]), importances[indices], color = \"r\", yerr = std[indices], align = \"center\")\n",
    "\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc10ddfb",
   "metadata": {},
   "source": [
    "# 1. LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0d52bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state=42)\n",
    "\n",
    "print(f\"Train data: {X_train.shape, y_train.shape}\")\n",
    "print(f\"Test data: {X_test.shape, y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2150df56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regresión algorithm\n",
    "\n",
    "regresion_lineal = LinearRegression()\n",
    "regresion_lineal.fit(X_train, y_train)\n",
    "\n",
    "# Finding coef\n",
    "\n",
    "print (\"weights:\", regresion_lineal.coef_)\n",
    "print (\"w_0:\", regresion_lineal.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c99e4b",
   "metadata": {},
   "source": [
    "## Predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f715d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = regresion_lineal.predict(X_test)\n",
    "\n",
    "for i, j in zip(yhat[:5], y_test[:5]):\n",
    "    print(f\"Predicción:{i} \\tValor real:{j}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be686f8f",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301fd49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sklearn tiene las formulas de algunas métricas en funciones.\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd09a23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relative Absolute Error\n",
    "RAE = np.sum(np.abs(np.subtract(y_test, yhat))) / np.sum(np.abs(np.subtract(y_test, np.mean(y_test))))\n",
    "\n",
    "# Relative Square Error\n",
    "RSE = np.sum(np.square(np.subtract(y_test, yhat))) / np.sum(np.square(np.subtract(y_test, np.mean(y_test))))\n",
    "\n",
    "# Adjusted R**2\n",
    "r2_ajustada = 1 - (1 - regresion_lineal.score(X_test, y_test))*(len(y_test) - 1)/(len(y_test) - X_test.shape[1] - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67ece12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MAE:\\t {mean_absolute_error(yhat, y_test)}\")\n",
    "print(f\"MSE:\\t {mean_squared_error(yhat, y_test)}\")\n",
    "print(f\"R**2:\\t {r2_score(yhat, y_test)}\")\n",
    "print(f\"RAE:\\t {RAE}\")\n",
    "print(f\"RSE:\\t {RSE}\")\n",
    "print(f\"Adjusted R**2:\\t {r2_ajustada}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8809447a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Veamos los valores de yhat, y_test y su diferencia\n",
    "\n",
    "# df_pred = pd.DataFrame()\n",
    "\n",
    "# df_pred[\"y_test\"] = scaler_y.inverse_transform([y_test]).flatten()\n",
    "# df_pred[\"yhat\"] = scaler_y.inverse_transform([yhat]).flatten()\n",
    "\n",
    "# df_pred[\"diferencia\"] = round(abs((df_pred[\"y_test\"] - df_pred[\"yhat\"]) / df_pred[\"y_test\"] * 100), 4)\n",
    "\n",
    "# df_pred = df_pred.sort_values(\"diferencia\")\n",
    "\n",
    "# df_pred.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a236c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pred.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e301cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance btw real and predicted values\n",
    "\n",
    "plt.figure(figsize = (8, 5))\n",
    "\n",
    "sns.scatterplot(x = y_test.flatten(), y = yhat.flatten(), alpha = 0.5, color = \"blue\")\n",
    "\n",
    "plt.xlabel(\"Valores Reales (y_train)\", size = 18)\n",
    "plt.ylabel(\"Predicciones (yhat)\", size = 18)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ee7d79",
   "metadata": {},
   "source": [
    "# 2. KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45242239",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2ab59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsRegressor(n_neighbors = 7)\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ef795e",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(X_test)\n",
    "\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b798f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MAE:\\t {mean_absolute_error(yhat, y_test)}\")\n",
    "print(f\"MSE:\\t {mean_squared_error(yhat, y_test)}\")\n",
    "print(f\"R**2:\\t {r2_score(yhat, y_test)}\")\n",
    "print(f\"RAE:\\t {RAE}\")\n",
    "print(f\"RSE:\\t {RSE}\")\n",
    "print(f\"Adjusted R**2:\\t {r2_ajustada}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f404f8d7",
   "metadata": {},
   "source": [
    "# 3. DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946c0ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a170d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeRegressor(max_depth = 10, max_features = \"sqrt\", random_state = 42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa273264",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(X_test)\n",
    "\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9f1471",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MAE:\\t {mean_absolute_error(yhat, y_test)}\")\n",
    "print(f\"MSE:\\t {mean_squared_error(yhat, y_test)}\")\n",
    "print(f\"R**2:\\t {r2_score(yhat, y_test)}\")\n",
    "print(f\"RAE:\\t {RAE}\")\n",
    "print(f\"RSE:\\t {RSE}\")\n",
    "print(f\"Adjusted R**2:\\t {r2_ajustada}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf8ce5b",
   "metadata": {},
   "source": [
    "# 4. RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181d6eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8d8b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_estimators = 200, max_depth = 10, random_state = 42, min_samples_split = 20)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5024367",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(X_test)\n",
    "\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c40dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MAE:\\t {mean_absolute_error(yhat, y_test)}\")\n",
    "print(f\"MSE:\\t {mean_squared_error(yhat, y_test)}\")\n",
    "print(f\"R**2:\\t {r2_score(yhat, y_test)}\")\n",
    "print(f\"RAE:\\t {RAE}\")\n",
    "print(f\"RSE:\\t {RSE}\")\n",
    "print(f\"Adjusted R**2:\\t {r2_ajustada}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa80f95",
   "metadata": {},
   "source": [
    "# 4. AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd686098",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef5b7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# model = AdaBoostRegressor(base_estimator = RandomForestRegressor(n_estimators      = 200,\n",
    "#                                                                  max_depth         = 10,\n",
    "#                                                                  min_samples_split = 20,\n",
    "#                                                                  n_jobs            = -1),\n",
    "#                           n_estimators   = 200)\n",
    "\n",
    "# model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4729ea6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(X_test)\n",
    "\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3b750c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MAE:\\t {mean_absolute_error(yhat, y_test)}\")\n",
    "print(f\"MSE:\\t {mean_squared_error(yhat, y_test)}\")\n",
    "print(f\"R**2:\\t {r2_score(yhat, y_test)}\")\n",
    "print(f\"RAE:\\t {RAE}\")\n",
    "print(f\"RSE:\\t {RSE}\")\n",
    "print(f\"Adjusted R**2:\\t {r2_ajustada}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0861fc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.base_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c6d7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model.estimator_errors_, marker = \"o\", color = \"red\", linestyle = \"\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a537272f",
   "metadata": {},
   "outputs": [],
   "source": [
    "importancia = model.feature_importances_\n",
    "\n",
    "for i in np.argsort(importancia)[::-1]:\n",
    "    print(i, importancia[i], df_columns_chosen.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5019aac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_columns_chosen.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e794cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edd9430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893ed450",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e084e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e1d38c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2aada5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# model = RandomForestClassifier()\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# # Exportar modelos usando pickle con extensión \".sav\"\n",
    "# with open(\"random_forest_clf.sav\", \"wb\") as file:\n",
    "#     pickle.dump(model, file)\n",
    "    \n",
    "# # Importar modelos usando pickle con extensión \".sav\"\n",
    "# with open(\"random_forest_clf.sav\", \"rb\") as file:\n",
    "#     model = pickle.load(file)\n",
    "    \n",
    "# # También se puede usar extensión \".pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487e8b65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f55367",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb0d985",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c9d463c",
   "metadata": {},
   "source": [
    "# Mapa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8441376d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8822fcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['neighbourhood_group_cleansed'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c2cd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"neighbourhoods.geojson\", \"r\") as file:\n",
    "    \n",
    "#     geojson = file.read()\n",
    "    \n",
    "# pprint(geojson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3572486d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_map = df.groupby('neighbourhood_group_cleansed', as_index=False).mean()\n",
    "# df_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0db3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_map = df_map[df_map[\"price\"]<200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e27abff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6542a3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.histplot(df_map[\"price\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f42cfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# world_map = folium.Map(location = [40.18893909782826, -3.938873736090105], zoom_start =12)\n",
    "\n",
    "# folium.Choropleth(geo_data     = geojson,\n",
    "#                   data         = df_map,\n",
    "#                   columns      = [\"neighbourhood_group_cleansed\", \"price\"],\n",
    "#                   key_on       = \"feature.properties.neighbourhood_group\",\n",
    "#                   fill_color   = \"Blues_r\", \n",
    "#                   fill_opacity = 0.7, \n",
    "#                   line_opacity = 0.2,\n",
    "#                   legend_name  = \"Precio airbnb\",\n",
    "#                   bins         = 253,\n",
    "#                   highlight    = True).add_to(world_map)\n",
    "\n",
    "# world_map"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
