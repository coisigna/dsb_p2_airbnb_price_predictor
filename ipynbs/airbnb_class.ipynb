{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "633b15de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "import folium\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from collections import Counter\n",
    "\n",
    "# Modelos\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# MÃ©tricas\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67785752",
   "metadata": {},
   "outputs": [],
   "source": [
    "class airbnb:\n",
    "    \n",
    "    def __init__(self, csvs, city_names):\n",
    "            \n",
    "            self.l_dfs = list()\n",
    "            \n",
    "            for enum, dataset in enumerate(csvs):\n",
    "                \n",
    "                self.l_dfs.append(pd.read_csv(dataset))\n",
    "                \n",
    "                self.l_dfs[enum].drop(\"source\", axis = 1, inplace = True)\n",
    "                \n",
    "                self.l_dfs[enum][\"city\"] = city_names[enum].lower()\n",
    "        \n",
    "            self.df = pd.concat(self.l_dfs)\n",
    "            \n",
    "            print(\"Instance created!\")\n",
    "            \n",
    "    def return_initial_df(self):\n",
    "    \n",
    "        return self.df\n",
    "    \n",
    "    def display__initial_df(self):\n",
    "    \n",
    "        display(self.df)\n",
    "\n",
    "    def clean_tested_columns(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        Sets predefined columns, transforms price to a float column and separates bathroom_text \n",
    "        into 3 different categories, private, shared and unknown.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Sets predefined columns\n",
    "        \n",
    "        tested_cols = ['neighbourhood_cleansed', 'city',\n",
    "                       'room_type', 'accommodates', 'availability_365',\n",
    "                       'bathrooms_text', 'bedrooms', 'beds', 'amenities', 'price',\n",
    "                       'minimum_nights', 'maximum_nights',\n",
    "                       'number_of_reviews', 'reviews_per_month', 'host_total_listings_count']\n",
    "        \n",
    "        self.df_cleaned = self.df[tested_cols]\n",
    "        \n",
    "        # Transforms price to a float column\n",
    "        \n",
    "        self.df_cleaned[\"price\"] = self.df_cleaned[\"price\"].apply(lambda x: float(x.strip(\"$\").replace(',', '')) if pd.notnull(x) else x).values\n",
    "            \n",
    "        # Get numbers out of bathroom_text columns\n",
    "        \n",
    "        self.df_cleaned = self.df_cleaned[self.df_cleaned[\"bathrooms_text\"].isnull() == False]\n",
    "\n",
    "        l_nums = [re.findall(r'\\d+',i) for i in self.df_cleaned[\"bathrooms_text\"].values]\n",
    "\n",
    "        l_nums_completed = []\n",
    "\n",
    "        for i in l_nums:\n",
    "\n",
    "            if len(i) > 1:\n",
    "\n",
    "                l_nums_completed.append('.'.join(i))\n",
    "\n",
    "            elif len(i) == 0:\n",
    "\n",
    "                l_nums_completed.append('0')\n",
    "\n",
    "            else:\n",
    "\n",
    "                l_nums_completed.append(i[0])\n",
    "                \n",
    "        # Replace bathrooms_text with floats\n",
    "        \n",
    "        self.df_cleaned[\"bathrooms_text\"] = l_nums_completed\n",
    "\n",
    "        self.df_cleaned[\"bathrooms_text\"] = self.df_cleaned[\"bathrooms_text\"].astype(\"float64\")\n",
    "        \n",
    "        # Amenities\n",
    "                \n",
    "        l_amenities_cleaned = list()\n",
    "        \n",
    "        for i in self.df_cleaned[\"amenities\"]:\n",
    "\n",
    "            l_amenities_cleaned.append(json.loads(i))\n",
    "\n",
    "        # Most relevant amenities, detailed analysis in the EDA file\n",
    "\n",
    "        l_amenities_valuables = ['Long term stays allowed','Cooking basics','Dishes and silverware','Essentials','Coffee maker','Hair dryer','Microwave','Refrigerator','Heating','Air conditioning']\n",
    "\n",
    "        for j in l_amenities_valuables:\n",
    "\n",
    "            self.df_cleaned[j] = [1 if j in i else 0 for i in l_amenities_cleaned]\n",
    "\n",
    "        self.df_cleaned.drop(\"amenities\", axis =1, inplace=True)\n",
    "    \n",
    "        # Room type\n",
    "        \n",
    "        self.df_cleaned = self.df_cleaned[self.df_cleaned[\"room_type\"] != \"Hotel room\"]\n",
    "        self.df_cleaned = pd.concat([self.df_cleaned, pd.get_dummies(data = self.df_cleaned[\"room_type\"])], axis = 1).drop(\"room_type\", axis = 1)\n",
    "        \n",
    "        self.df_cleaned.dropna(inplace = True)\n",
    "        \n",
    "    def return_cleaned(self):\n",
    "        \n",
    "        return self.df_cleaned\n",
    "    \n",
    "    def display_cleaned(self):\n",
    "        \n",
    "        display(self.df_cleaned)\n",
    "    \n",
    "    def remove_outliers(self, accommodates = 8, bathrooms_min = 1, bathrooms_max = 2, bedrooms = 4, beds_min = 1, beds_max = 5, minimum_nights = 30,\n",
    "                       maximum_nights = 70000, nreviews = 375, reviews_pmonth = 9, price = 350, htlc = 50000):\n",
    "\n",
    "        self.df_cleaned = self.df_cleaned[self.df_cleaned[\"accommodates\"] <= accommodates]\n",
    "        self.df_cleaned = self.df_cleaned[self.df_cleaned[\"bathrooms_text\"].between(bathrooms_min, bathrooms_max)]\n",
    "        self.df_cleaned = self.df_cleaned[self.df_cleaned[\"bedrooms\"] <= bedrooms]\n",
    "        self.df_cleaned = self.df_cleaned[self.df_cleaned[\"beds\"].between(beds_min, beds_max)]\n",
    "        self.df_cleaned = self.df_cleaned[self.df_cleaned[\"minimum_nights\"] <= minimum_nights]\n",
    "        self.df_cleaned = self.df_cleaned[self.df_cleaned[\"maximum_nights\"] <= maximum_nights]\n",
    "        self.df_cleaned = self.df_cleaned[self.df_cleaned[\"number_of_reviews\"] <= nreviews]\n",
    "        self.df_cleaned = self.df_cleaned[self.df_cleaned[\"reviews_per_month\"] <= reviews_pmonth]\n",
    "        self.df_cleaned = self.df_cleaned[self.df_cleaned[\"price\"] <= price]\n",
    "        self.df_cleaned = self.df_cleaned[self.df_cleaned[\"host_total_listings_count\"] <= htlc]\n",
    "\n",
    "        return self.df_cleaned\n",
    "    \n",
    "    def display_outliers(self):\n",
    "        \n",
    "        for i in self.df_cleaned.columns:\n",
    "    \n",
    "            print(i)\n",
    "            sns.kdeplot(self.df_cleaned[i])\n",
    "            plt.show()\n",
    "\n",
    "    def label_encoding(self):\n",
    "        \n",
    "        city_encoder = LabelEncoder()\n",
    "        self.df_cleaned[\"city\"] = city_encoder.fit_transform(self.df_cleaned[\"city\"])\n",
    "        neighbourhood_encoder = LabelEncoder()\n",
    "        self.df_cleaned[\"neighbourhood_cleansed\"] = neighbourhood_encoder.fit_transform(self.df_cleaned[\"neighbourhood_cleansed\"])\n",
    "        \n",
    "        return self.df_cleaned\n",
    "    \n",
    "    def normalize(self):\n",
    "        \n",
    "        x_scaler = MinMaxScaler()\n",
    "        self.df_cleaned[self.df_cleaned.drop(\"price\", axis = 1).columns] = x_scaler.fit_transform(self.df_cleaned[self.df_cleaned.drop(\"price\", axis = 1).columns])\n",
    "\n",
    "        y_scaler = MinMaxScaler()\n",
    "        self.df_cleaned[\"price\"] = y_scaler.fit_transform(self.df_cleaned[[\"price\"]]).flatten()\n",
    "        \n",
    "        return self.df_cleaned\n",
    "    \n",
    "    def tts(self):\n",
    "        \n",
    "        self.X = self.df_cleaned.drop([\"price\"], axis = 1)\n",
    "        self.y = self.df_cleaned[\"price\"]\n",
    "                \n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "        print(f\"X_train: {self.X_train.shape} | y_train: {self.y_train.shape}\")\n",
    "        print(f\"X_test: {self.X_test.shape} | y_test: {self.y_test.shape}\")\n",
    "    \n",
    "    def train_model(self):\n",
    "        \n",
    "        models = [LinearRegression(), KNeighborsRegressor(), DecisionTreeRegressor(),\n",
    "                 RandomForestRegressor(), SVR(), AdaBoostRegressor(), GradientBoostingRegressor()]\n",
    "                \n",
    "        metrics = list()\n",
    "        \n",
    "        for model in models:\n",
    "            \n",
    "            # fit\n",
    "            \n",
    "            model.fit(self.X_train, self.y_train)\n",
    "\n",
    "            # predict\n",
    "            \n",
    "            self.yhat = model.predict(self.X_test)\n",
    "            \n",
    "            # metrics\n",
    "            \n",
    "            r2 = r2_score(self.y_test, self.yhat)\n",
    "            mse = mean_squared_error(self.y_test, self.yhat)\n",
    "        \n",
    "            metrics.append([str(model), r2, mse, model])\n",
    "            \n",
    "        self.df_metrics = pd.DataFrame(data = metrics, columns = [\"model_name\", \"r2\", \"mse\", \"model\"])\n",
    "        self.df_metrics.sort_values(by = \"r2\", ascending = False, inplace= True)\n",
    "        \n",
    "    def return_metrics(self):\n",
    "        \n",
    "        return self.df_metrics\n",
    "    \n",
    "    def display_metrics(self):\n",
    "        \n",
    "        display(self.df_metrics)\n",
    "        \n",
    "    def model_feature_importances(self, model):\n",
    "        \n",
    "        importances = np.argsort(model.feature_importances_)[::-1]\n",
    "        d_importances = dict()\n",
    "        \n",
    "        for i in importances:\n",
    "\n",
    "            d_importances[i] = [model.feature_importances_[i]*100, self.df_cleaned.drop(\"price\", axis = 1).columns[i]]\n",
    "            print(i, model.feature_importances_[i]*100, self.df_cleaned.drop(\"price\", axis = 1).columns[i])\n",
    "            \n",
    "        return d_importances\n",
    "    \n",
    "    def grid_search_cv_tuning(self):\n",
    "        \n",
    "        model = RandomForestRegressor()\n",
    "        \n",
    "        params = {\"n_estimators\" : [i for i in range(100, 1001, 50)],\n",
    "                  \"max_depth\"    : [8, 10, 12, 14, 16],\n",
    "                  \"max_features\" : [\"log2\", \"sqrt\"]}\n",
    "\n",
    "        scorers = {\"r2\", \"neg_mean_squared_error\"}\n",
    "\n",
    "        grid_solver = GridSearchCV(estimator  = model, \n",
    "                                   param_grid = params, \n",
    "                                   scoring    = scorers,\n",
    "                                   cv         = 10,\n",
    "                                   refit      = \"r2\",\n",
    "                                   n_jobs     = -1, \n",
    "                                   verbose    = 2)\n",
    "\n",
    "        self.model_result = grid_solver.fit(X_train, y_train)\n",
    "        \n",
    "    def return_model_result_gcv(self):\n",
    "        \n",
    "        return self.model_result\n",
    "        \n",
    "    def grid_search_cv_validation(self):\n",
    "        \n",
    "        l_validations = [self.model_result.best_estimator_,\n",
    "                         self.model_result.cv_results_[\"mean_test_r2\"].max(),\n",
    "                         self.model_result.best_score_]\n",
    "        self.df_validations = pd.DataFrame(data = l_validations, columns = [\"Best Estimator\",\n",
    "                                                                            \"Mean Test R**2\",\n",
    "                                                                            \"Best Score\"])\n",
    "    def return_validations_gcv(self):\n",
    "        \n",
    "        return self.df_validations\n",
    "    \n",
    "    def final_trial_model(self):\n",
    "        \n",
    "        '''It trains the best model with the features recomended'''\n",
    "        \n",
    "        model = RandomForestRegressor(max_depth=16, max_features='sqrt', n_estimators=650, random_state = 42)\n",
    "        model.fit(self.X_train, self.y_train)\n",
    "        \n",
    "        self.yhat = model.predict(self.X_test)\n",
    "    \n",
    "        return f\"r**2 = {r2_score(self.y_test, self.yhat)}\"\n",
    "    \n",
    "    def train_final_model(self, max_depth, max_features, n_estimators,random_state):\n",
    "        \n",
    "        '''Returns the definitive model'''\n",
    "        \n",
    "        self.X_def = self.df_cleaned.drop([\"price\"], axis = 1)\n",
    "        self.y_def = self.df_cleaned[\"price\"]\n",
    "        \n",
    "        model = RandomForestRegressor(max_depth = max_depth, max_features = max_features, n_estimators = n_estimators, random_state = random_state)\n",
    "        model.fit(self.X_def, self.y_def)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def predict(self, array):  \n",
    "        \n",
    "        '''Predicts the price given a cleaned array with te features needed'''\n",
    "        \n",
    "        self.price_predicted = y_scaler.inverse_transform([model.predict([array])])\n",
    "    \n",
    "    def return_prediction(self):\n",
    "        \n",
    "        \n",
    "        return self.price_predicted\n",
    "    \n",
    "    def save_model(self, name, ext, model):\n",
    "    \n",
    "        with open(f\"{name}.{ext}\", \"wb\") as file:\n",
    "            pickle.dump(model)\n",
    "            \n",
    "    def load_model(self, name, ext):\n",
    "        \n",
    "        with open(f\"{name}.{ext}\", \"rb\") as file:\n",
    "            self.model = pickle.load(file)\n",
    "            \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5cbde06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets used\n",
    "madrid = \"datasets/madrid.csv\"\n",
    "barcelona = \"datasets/barcelona.csv\"\n",
    "london = \"datasets/london.csv\"\n",
    "\n",
    "d_csvs, d_names = dict(), dict()\n",
    "\n",
    "d_csvs[\"csvs1\"] = [madrid, barcelona]\n",
    "d_csvs[\"csvs2\"] = [london]\n",
    "\n",
    "d_names[\"names1\"] = [\"madrid\",\"barcelona\"]\n",
    "d_names[\"names2\"] = [\"london\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39fa3cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance created!\n",
      "Instance created!\n",
      "CPU times: user 3.06 s, sys: 266 ms, total: 3.32 s\n",
      "Wall time: 3.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "d_dfs = dict()\n",
    "\n",
    "for i in range(1,3):\n",
    "    \n",
    "    d_dfs[f\"instance{i}\"] = airbnb(d_csvs[f\"csvs{i}\"],d_names[f\"names{i}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef784bd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/10/5nbnv2696vlgb605wf3g6wwh0000gn/T/ipykernel_6506/2513089042.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.df_cleaned[\"price\"] = self.df_cleaned[\"price\"].apply(lambda x: float(x.strip(\"$\").replace(',', '')) if pd.notnull(x) else x).values\n",
      "/var/folders/10/5nbnv2696vlgb605wf3g6wwh0000gn/T/ipykernel_6506/2513089042.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.df_cleaned[\"price\"] = self.df_cleaned[\"price\"].apply(lambda x: float(x.strip(\"$\").replace(',', '')) if pd.notnull(x) else x).values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.4 s, sys: 86.8 ms, total: 1.48 s\n",
      "Wall time: 1.58 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for instance in d_dfs.values():\n",
    "    \n",
    "    instance.clean_tested_columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "552ed6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 Âµs, sys: 0 ns, total: 5 Âµs\n",
      "Wall time: 7.39 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "l_dfs = list()\n",
    "\n",
    "for instance in d_dfs.values():\n",
    "    \n",
    "    l_dfs.append(instance.return_cleaned())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09199853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 53.9 ms, sys: 3.92 ms, total: 57.8 ms\n",
      "Wall time: 66.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for instance in d_dfs.values():\n",
    "    \n",
    "    instance.remove_outliers()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca68b624",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for instance in d_dfs.values():\n",
    "    instance.label_encoding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb3a2872",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for instance in d_dfs.values():\n",
    "    instance.normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce7c622d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (16786, 25) | y_train: (16786,)\n",
      "X_test: (4197, 25) | y_test: (4197,)\n",
      "X_train: (33600, 25) | y_train: (33600,)\n",
      "X_test: (8400, 25) | y_test: (8400,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for instance in d_dfs.values():\n",
    "    instance.tts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75870031",
   "metadata": {},
   "outputs": [],
   "source": [
    "for instance in d_dfs.values():\n",
    "    instance.tts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198deae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for instance in d_dfs.values():\n",
    "    instance.grid_search_cv_tuning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca56a627",
   "metadata": {},
   "outputs": [],
   "source": [
    "for instance in d_dfs.values():\n",
    "    instance.grid_search_cv_validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d8d8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_models_resulted = dict()\n",
    "\n",
    "for name,instance in d_dfs.items():\n",
    "    d_models_resulted[name] = instance.return_model_result_gcv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20f0978",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_validations_resulted = dict()\n",
    "\n",
    "for name, instance in d_dfs.items():\n",
    "    d_validations_resulted[name] = instance.return_validations_gcv()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
