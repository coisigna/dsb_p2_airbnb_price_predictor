{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "633b15de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "import folium\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from collections import Counter\n",
    "from IPython.display import display\n",
    "\n",
    "# Modelos\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Métricas\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import pickle\n",
    "\n",
    "# import pys/airbnb_class.py as ca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67785752",
   "metadata": {},
   "outputs": [],
   "source": [
    "class airbnb:\n",
    "    \n",
    "    def __init__(self, data, city_names = None, file = \"csv\"):\n",
    "                    \n",
    "        if (file == \"csv\") and (city_names is not None):\n",
    "            \n",
    "            self.l_dfs = list()\n",
    "            \n",
    "            for enum, dataset in enumerate(data):\n",
    "                \n",
    "                self.l_dfs.append(pd.read_csv(dataset))\n",
    "                \n",
    "                self.l_dfs[enum].drop(\"source\", axis = 1, inplace = True)\n",
    "                \n",
    "                self.l_dfs[enum][\"city\"] = city_names[enum].lower()\n",
    "        \n",
    "            self.df = pd.concat(self.l_dfs)\n",
    "            \n",
    "            print(\"Instance created!\")\n",
    "            \n",
    "        elif file == \"dataframe\":\n",
    "            \n",
    "            self.l_dfs = list()\n",
    "\n",
    "            for enum, dataframe in enumerate(data):\n",
    "                \n",
    "                self.l_dfs.append(dataframe)\n",
    "                                        \n",
    "            self.df = pd.concat(self.l_dfs)\n",
    "            \n",
    "            print(\"Instance created!\")\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            print(\"Only csv or dataframe are valid inputs, and city_names cannot be empty\")\n",
    "            \n",
    "    def return_initial_df(self):\n",
    "    \n",
    "        return self.df\n",
    "    \n",
    "    def display__initial_df(self):\n",
    "    \n",
    "        display(self.df)\n",
    "\n",
    "    def clean_tested_columns(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        Sets predefined columns, transforms price to a float column and separates bathroom_text \n",
    "        into 3 different categories, private, shared and unknown.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Sets predefined columns\n",
    "        \n",
    "        tested_cols = ['neighbourhood_cleansed', 'city',\n",
    "                       'room_type', 'accommodates', 'availability_365',\n",
    "                       'bathrooms_text', 'bedrooms', 'beds', 'amenities', 'price',\n",
    "                       'minimum_nights', 'maximum_nights',\n",
    "                       'number_of_reviews', 'reviews_per_month', 'host_total_listings_count']\n",
    "        \n",
    "        self.df_cleaned = self.df[tested_cols]\n",
    "        \n",
    "        # Transforms price to a float column\n",
    "        \n",
    "        self.df_cleaned[\"price\"] = self.df_cleaned[\"price\"].apply(lambda x: float(x.strip(\"$\").replace(',', '')) if pd.notnull(x) else x).values\n",
    "            \n",
    "        # Get numbers out of bathroom_text columns\n",
    "        \n",
    "        self.df_cleaned = self.df_cleaned[self.df_cleaned[\"bathrooms_text\"].isnull() == False]\n",
    "\n",
    "        l_nums = [re.findall(r'\\d+',i) for i in self.df_cleaned[\"bathrooms_text\"].values]\n",
    "\n",
    "        l_nums_completed = []\n",
    "\n",
    "        for i in l_nums:\n",
    "\n",
    "            if len(i) > 1:\n",
    "\n",
    "                l_nums_completed.append('.'.join(i))\n",
    "\n",
    "            elif len(i) == 0:\n",
    "\n",
    "                l_nums_completed.append('0')\n",
    "\n",
    "            else:\n",
    "\n",
    "                l_nums_completed.append(i[0])\n",
    "                \n",
    "        # Replace bathrooms_text with floats\n",
    "        \n",
    "        self.df_cleaned[\"bathrooms_text\"] = l_nums_completed\n",
    "\n",
    "        self.df_cleaned[\"bathrooms_text\"] = self.df_cleaned[\"bathrooms_text\"].astype(\"float64\")\n",
    "        \n",
    "        # Amenities\n",
    "                \n",
    "        l_amenities_cleaned = list()\n",
    "        \n",
    "        for i in self.df_cleaned[\"amenities\"]:\n",
    "\n",
    "            l_amenities_cleaned.append(json.loads(i))\n",
    "\n",
    "        # Most relevant amenities, detailed analysis in the EDA file\n",
    "\n",
    "        l_amenities_valuables = ['Long term stays allowed','Cooking basics','Dishes and silverware','Essentials','Coffee maker','Hair dryer','Microwave','Refrigerator','Heating','Air conditioning']\n",
    "\n",
    "        for j in l_amenities_valuables:\n",
    "\n",
    "            self.df_cleaned[j] = [1 if j in i else 0 for i in l_amenities_cleaned]\n",
    "\n",
    "        self.df_cleaned.drop(\"amenities\", axis =1, inplace=True)\n",
    "    \n",
    "        # Room type\n",
    "        \n",
    "        self.df_cleaned = self.df_cleaned[self.df_cleaned[\"room_type\"] != \"Hotel room\"]\n",
    "        self.df_cleaned = pd.concat([self.df_cleaned, pd.get_dummies(data = self.df_cleaned[\"room_type\"])], axis = 1).drop(\"room_type\", axis = 1)\n",
    "        \n",
    "        self.df_cleaned.dropna(inplace = True)\n",
    "        \n",
    "    def return_cleaned(self):\n",
    "        \n",
    "        return self.df_cleaned\n",
    "    \n",
    "    def display_cleaned(self):\n",
    "        \n",
    "        display(self.df_cleaned)\n",
    "    \n",
    "    def remove_outliers(self, accommodates = 8, bathrooms_min = 1, bathrooms_max = 2, bedrooms = 4, beds_min = 1, beds_max = 5, minimum_nights = 30,\n",
    "                       maximum_nights = 70000, nreviews = 375, reviews_pmonth = 9, price = 350, htlc = 50000):\n",
    "\n",
    "        self.df_cleaned = self.df_cleaned[self.df_cleaned[\"accommodates\"] <= accommodates]\n",
    "        self.df_cleaned = self.df_cleaned[self.df_cleaned[\"bathrooms_text\"].between(bathrooms_min, bathrooms_max)]\n",
    "        self.df_cleaned = self.df_cleaned[self.df_cleaned[\"bedrooms\"] <= bedrooms]\n",
    "        self.df_cleaned = self.df_cleaned[self.df_cleaned[\"beds\"].between(beds_min, beds_max)]\n",
    "        self.df_cleaned = self.df_cleaned[self.df_cleaned[\"minimum_nights\"] <= minimum_nights]\n",
    "        self.df_cleaned = self.df_cleaned[self.df_cleaned[\"maximum_nights\"] <= maximum_nights]\n",
    "        self.df_cleaned = self.df_cleaned[self.df_cleaned[\"number_of_reviews\"] <= nreviews]\n",
    "        self.df_cleaned = self.df_cleaned[self.df_cleaned[\"reviews_per_month\"] <= reviews_pmonth]\n",
    "        self.df_cleaned = self.df_cleaned[self.df_cleaned[\"price\"] <= price]\n",
    "        self.df_cleaned = self.df_cleaned[self.df_cleaned[\"host_total_listings_count\"] <= htlc]\n",
    "\n",
    "        return self.df_cleaned\n",
    "    \n",
    "    def display_outliers(self):\n",
    "        \n",
    "        for i in self.df_cleaned.columns:\n",
    "    \n",
    "            print(i)\n",
    "            sns.kdeplot(self.df_cleaned[i])\n",
    "            plt.show()\n",
    "\n",
    "    def label_encoding(self, df = None):\n",
    "        \n",
    "        if df is None:\n",
    "            df = self.df_cleaned\n",
    "            \n",
    "        city_encoder = LabelEncoder()\n",
    "        df[\"city\"] = city_encoder.fit_transform(df[\"city\"])\n",
    "        neighbourhood_encoder = LabelEncoder()\n",
    "        df[\"neighbourhood_cleansed\"] = neighbourhood_encoder.fit_transform(df[\"neighbourhood_cleansed\"])\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def normalize(self, df = None):\n",
    "        \n",
    "        if df is None:\n",
    "            df = self.df_cleaned\n",
    "            \n",
    "        self.x_scaler = MinMaxScaler()\n",
    "        self.df_cleaned[self.df_cleaned.drop(\"price\", axis = 1).columns] = self.x_scaler.fit_transform(self.df_cleaned[self.df_cleaned.drop(\"price\", axis = 1).columns])\n",
    "\n",
    "        self.y_scaler = MinMaxScaler()\n",
    "        self.df_cleaned[\"price\"] = self.y_scaler.fit_transform(self.df_cleaned[[\"price\"]]).flatten()\n",
    "        \n",
    "        return self.df_cleaned\n",
    "    \n",
    "    def tts(self):\n",
    "        \n",
    "        self.X = self.df_cleaned.drop([\"price\"], axis = 1)\n",
    "        self.y = self.df_cleaned[\"price\"]\n",
    "                \n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "        print(f\"X_train: {self.X_train.shape} | y_train: {self.y_train.shape}\")\n",
    "        print(f\"X_test: {self.X_test.shape} | y_test: {self.y_test.shape}\")\n",
    "    \n",
    "    def train_model(self):\n",
    "        \n",
    "        models = [LinearRegression(), KNeighborsRegressor(), DecisionTreeRegressor(),\n",
    "                 RandomForestRegressor(), SVR(), AdaBoostRegressor(), GradientBoostingRegressor()]\n",
    "                \n",
    "        metrics = list()\n",
    "        \n",
    "        for model in models:\n",
    "            \n",
    "            # fit\n",
    "            \n",
    "            model.fit(self.X_train, self.y_train)\n",
    "\n",
    "            # predict\n",
    "            \n",
    "            self.yhat = model.predict(self.X_test)\n",
    "            \n",
    "            # metrics\n",
    "            \n",
    "            r2 = r2_score(self.y_test, self.yhat)\n",
    "            mse = mean_squared_error(self.y_test, self.yhat)\n",
    "        \n",
    "            metrics.append([str(model), r2, mse, model])\n",
    "            \n",
    "        self.df_metrics = pd.DataFrame(data = metrics, columns = [\"model_name\", \"r2\", \"mse\", \"model\"])\n",
    "        self.df_metrics.sort_values(by = \"r2\", ascending = False, inplace= True)\n",
    "        \n",
    "    def return_metrics(self):\n",
    "        \n",
    "        return self.df_metrics\n",
    "    \n",
    "    def display_metrics(self):\n",
    "        \n",
    "        display(self.df_metrics)\n",
    "        \n",
    "    def model_feature_importances(self, model):\n",
    "        \n",
    "        importances = np.argsort(model.feature_importances_)[::-1]\n",
    "        d_importances = dict()\n",
    "        \n",
    "        for i in importances:\n",
    "\n",
    "            d_importances[i] = [model.feature_importances_[i]*100, self.df_cleaned.drop(\"price\", axis = 1).columns[i]]\n",
    "            print(i, model.feature_importances_[i]*100, self.df_cleaned.drop(\"price\", axis = 1).columns[i])\n",
    "            \n",
    "        return d_importances\n",
    "    \n",
    "    def grid_search_cv_tuning(self):\n",
    "        \n",
    "        model = RandomForestRegressor()\n",
    "        \n",
    "        params = {\"n_estimators\" : [i for i in range(100, 1001, 50)],\n",
    "                  \"max_depth\"    : [8, 10, 12, 14, 16],\n",
    "                  \"max_features\" : [\"log2\", \"sqrt\"]}\n",
    "\n",
    "        scorers = {\"r2\", \"neg_mean_squared_error\"}\n",
    "\n",
    "        grid_solver = GridSearchCV(estimator  = model, \n",
    "                                   param_grid = params, \n",
    "                                   scoring    = scorers,\n",
    "                                   cv         = 10,\n",
    "                                   refit      = \"r2\",\n",
    "                                   n_jobs     = -1, \n",
    "                                   verbose    = 2)\n",
    "\n",
    "        self.model_result = grid_solver.fit(self.X_train, self.y_train)\n",
    "        \n",
    "        d_validations = {\"Best Estimator\" : self.model_result.best_estimator_,\n",
    "                         \"Mean Test R**2\" : self.model_result.cv_results_[\"mean_test_r2\"].max(),\n",
    "                         \"Best Score\"     : self.model_result.best_score_}\n",
    "        \n",
    "        self.df_validations = pd.DataFrame(data    = d_validations.items(), \n",
    "                                           columns = [\"Validation\",\"Result\"])\n",
    "        \n",
    "    def return_model_result_gcv(self):\n",
    "        \n",
    "        return self.model_result\n",
    "        \n",
    "    def return_validations_gcv(self):\n",
    "        \n",
    "        return self.df_validations\n",
    "                                           \n",
    "    def return_validations_gcv(self):\n",
    "        \n",
    "        return self.df_validations\n",
    "    \n",
    "    def final_trial_model(self, max_depth = 16, max_features = 'sqrt', n_estimators = 800, random_state = 42):\n",
    "        \n",
    "        '''It trains the best model with the features recomended'''\n",
    "        \n",
    "        model = RandomForestRegressor(max_depth, max_features, n_estimators, random_state)\n",
    "        model.fit(self.X_train, self.y_train)\n",
    "        \n",
    "        self.yhat = model.predict(self.X_test)\n",
    "    \n",
    "        return f\"r**2 = {r2_score(self.y_test, self.yhat)}\"\n",
    "    \n",
    "    def train_final_model(self, max_depth, max_features, n_estimators,random_state):\n",
    "        \n",
    "        '''Returns the definitive model'''\n",
    "        \n",
    "        self.X_def = self.df_cleaned.drop([\"price\"], axis = 1)\n",
    "        self.y_def = self.df_cleaned[\"price\"]\n",
    "        \n",
    "        model = RandomForestRegressor(max_depth = max_depth, max_features = max_features, n_estimators = n_estimators, random_state = random_state)\n",
    "        model.fit(self.X_def, self.y_def)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def predict(self, array, model):  \n",
    "        \n",
    "        '''Predicts the price given a cleaned array with te features needed'''\n",
    "        \n",
    "        self.price_predicted = self.y_scaler.inverse_transform(model.predict([array]))\n",
    "    \n",
    "    def return_prediction(self):\n",
    "        \n",
    "        return self.price_predicted\n",
    "    \n",
    "    def save_model(self, name, ext, model):\n",
    "    \n",
    "        with open(f\"{name}.{ext}\", \"wb\") as file:\n",
    "            pickle.dump(model, file)\n",
    "            \n",
    "    def load_model(self, name, ext):\n",
    "        \n",
    "        with open(f\"{name}.{ext}\", \"rb\") as file:\n",
    "            self.model = pickle.load(file)\n",
    "            \n",
    "        return self.model\n",
    "            \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5cbde06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets used\n",
    "madrid = \"datasets/madrid.csv\"\n",
    "barcelona = \"datasets/barcelona.csv\"\n",
    "london = \"datasets/london.csv\"\n",
    "\n",
    "d_csvs, d_names = dict(), dict()\n",
    "\n",
    "d_csvs[\"csvs1\"] = [madrid, barcelona]\n",
    "d_csvs[\"csvs2\"] = [london]\n",
    "\n",
    "d_names[\"names1\"] = [\"madrid\",\"barcelona\"]\n",
    "d_names[\"names2\"] = [\"london\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42370d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance created!\n",
      "Instance created!\n",
      "CPU times: user 2.6 s, sys: 218 ms, total: 2.82 s\n",
      "Wall time: 2.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "## Init instances\n",
    "\n",
    "d_dfs = dict()\n",
    "\n",
    "for i in range(1,3):\n",
    "    \n",
    "    d_dfs[f\"instance{i}\"] = airbnb(d_csvs[f\"csvs{i}\"],d_names[f\"names{i}\"], \"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "901505ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/10/5nbnv2696vlgb605wf3g6wwh0000gn/T/ipykernel_2890/559563046.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.df_cleaned[\"price\"] = self.df_cleaned[\"price\"].apply(lambda x: float(x.strip(\"$\").replace(',', '')) if pd.notnull(x) else x).values\n",
      "/var/folders/10/5nbnv2696vlgb605wf3g6wwh0000gn/T/ipykernel_2890/559563046.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.df_cleaned[\"price\"] = self.df_cleaned[\"price\"].apply(lambda x: float(x.strip(\"$\").replace(',', '')) if pd.notnull(x) else x).values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.3 s, sys: 64.4 ms, total: 1.36 s\n",
      "Wall time: 1.37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "## Clean columns\n",
    "for instance in d_dfs.values():\n",
    "    \n",
    "    instance.clean_tested_columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7052a595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
      "Wall time: 5.96 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "## Return cleaned\n",
    "\n",
    "l_dfs = list()\n",
    "\n",
    "for instance in d_dfs.values():\n",
    "    \n",
    "    l_dfs.append(instance.return_cleaned())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09199853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39.4 ms, sys: 867 µs, total: 40.2 ms\n",
      "Wall time: 40 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "## Remove outliers\n",
    "\n",
    "for instance in d_dfs.values():\n",
    "    \n",
    "    instance.remove_outliers()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca68b624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.4 ms, sys: 672 µs, total: 22.1 ms\n",
      "Wall time: 21.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "## Label encoding\n",
    "\n",
    "for instance in d_dfs.values():\n",
    "    instance.label_encoding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb3a2872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40.8 ms, sys: 5.19 ms, total: 46 ms\n",
      "Wall time: 45.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "## Normalize\n",
    "\n",
    "for instance in d_dfs.values():\n",
    "    instance.normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce7c622d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (16786, 25) | y_train: (16786,)\n",
      "X_test: (4197, 25) | y_test: (4197,)\n",
      "X_train: (33600, 25) | y_train: (33600,)\n",
      "X_test: (8400, 25) | y_test: (8400,)\n",
      "CPU times: user 13.6 ms, sys: 2.54 ms, total: 16.1 ms\n",
      "Wall time: 16.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "## Train test split\n",
    "\n",
    "for instance in d_dfs.values():\n",
    "    instance.tts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6c3fc54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 39s, sys: 6.07 s, total: 1min 45s\n",
      "Wall time: 1min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "## Train model\n",
    "\n",
    "for instance in d_dfs.values():\n",
    "    instance.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62640d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
      "Wall time: 6.91 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "## Return metrics\n",
    "l_metrics = []\n",
    "\n",
    "for instance in d_dfs.values():\n",
    "    l_metrics.append(instance.return_metrics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6efa67a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>r2</th>\n",
       "      <th>mse</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestRegressor()</td>\n",
       "      <td>0.738403</td>\n",
       "      <td>0.012887</td>\n",
       "      <td>(DecisionTreeRegressor(max_features='auto', ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GradientBoostingRegressor()</td>\n",
       "      <td>0.670694</td>\n",
       "      <td>0.016222</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVR()</td>\n",
       "      <td>0.647817</td>\n",
       "      <td>0.017349</td>\n",
       "      <td>SVR()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNeighborsRegressor()</td>\n",
       "      <td>0.588164</td>\n",
       "      <td>0.020288</td>\n",
       "      <td>KNeighborsRegressor()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>0.574795</td>\n",
       "      <td>0.020947</td>\n",
       "      <td>LinearRegression()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTreeRegressor()</td>\n",
       "      <td>0.475588</td>\n",
       "      <td>0.025834</td>\n",
       "      <td>DecisionTreeRegressor()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AdaBoostRegressor()</td>\n",
       "      <td>0.409503</td>\n",
       "      <td>0.029089</td>\n",
       "      <td>(DecisionTreeRegressor(max_depth=3, random_sta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model_name        r2       mse  \\\n",
       "3      RandomForestRegressor()  0.738403  0.012887   \n",
       "6  GradientBoostingRegressor()  0.670694  0.016222   \n",
       "4                        SVR()  0.647817  0.017349   \n",
       "1        KNeighborsRegressor()  0.588164  0.020288   \n",
       "0           LinearRegression()  0.574795  0.020947   \n",
       "2      DecisionTreeRegressor()  0.475588  0.025834   \n",
       "5          AdaBoostRegressor()  0.409503  0.029089   \n",
       "\n",
       "                                               model  \n",
       "3  (DecisionTreeRegressor(max_features='auto', ra...  \n",
       "6  ([DecisionTreeRegressor(criterion='friedman_ms...  \n",
       "4                                              SVR()  \n",
       "1                              KNeighborsRegressor()  \n",
       "0                                 LinearRegression()  \n",
       "2                            DecisionTreeRegressor()  \n",
       "5  (DecisionTreeRegressor(max_depth=3, random_sta...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Metricas Madrid - Barcelona\n",
    "\n",
    "l_metrics[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d248b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>r2</th>\n",
       "      <th>mse</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestRegressor()</td>\n",
       "      <td>0.656074</td>\n",
       "      <td>0.014560</td>\n",
       "      <td>(DecisionTreeRegressor(max_features='auto', ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GradientBoostingRegressor()</td>\n",
       "      <td>0.637781</td>\n",
       "      <td>0.015335</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVR()</td>\n",
       "      <td>0.574450</td>\n",
       "      <td>0.018016</td>\n",
       "      <td>SVR()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNeighborsRegressor()</td>\n",
       "      <td>0.511806</td>\n",
       "      <td>0.020668</td>\n",
       "      <td>KNeighborsRegressor()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>0.508913</td>\n",
       "      <td>0.020791</td>\n",
       "      <td>LinearRegression()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AdaBoostRegressor()</td>\n",
       "      <td>0.332109</td>\n",
       "      <td>0.028276</td>\n",
       "      <td>(DecisionTreeRegressor(max_depth=3, random_sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTreeRegressor()</td>\n",
       "      <td>0.313806</td>\n",
       "      <td>0.029051</td>\n",
       "      <td>DecisionTreeRegressor()</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model_name        r2       mse  \\\n",
       "3      RandomForestRegressor()  0.656074  0.014560   \n",
       "6  GradientBoostingRegressor()  0.637781  0.015335   \n",
       "4                        SVR()  0.574450  0.018016   \n",
       "1        KNeighborsRegressor()  0.511806  0.020668   \n",
       "0           LinearRegression()  0.508913  0.020791   \n",
       "5          AdaBoostRegressor()  0.332109  0.028276   \n",
       "2      DecisionTreeRegressor()  0.313806  0.029051   \n",
       "\n",
       "                                               model  \n",
       "3  (DecisionTreeRegressor(max_features='auto', ra...  \n",
       "6  ([DecisionTreeRegressor(criterion='friedman_ms...  \n",
       "4                                              SVR()  \n",
       "1                              KNeighborsRegressor()  \n",
       "0                                 LinearRegression()  \n",
       "5  (DecisionTreeRegressor(max_depth=3, random_sta...  \n",
       "2                            DecisionTreeRegressor()  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## London\n",
    "\n",
    "l_metrics[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92b245b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 23.132949536471266 Entire home/apt\n",
      "2 12.599529650462902 accommodates\n",
      "1 10.215942768612095 city\n",
      "11 9.230282060924946 host_total_listings_count\n",
      "3 8.23619368680208 availability_365\n",
      "4 6.0999472444382405 bathrooms_text\n",
      "10 5.388723355576862 reviews_per_month\n",
      "0 4.979412275398448 neighbourhood_cleansed\n",
      "7 4.64194331944598 minimum_nights\n",
      "9 3.969519494101179 number_of_reviews\n",
      "8 2.6504142830820956 maximum_nights\n",
      "21 1.49085743637085 Air conditioning\n",
      "6 1.4427049351833332 beds\n",
      "5 1.1973446444737668 bedrooms\n",
      "14 0.7598289611541807 Dishes and silverware\n",
      "17 0.6328597560811051 Hair dryer\n",
      "13 0.5773244206367949 Cooking basics\n",
      "15 0.5334322260000017 Essentials\n",
      "16 0.5269481538456574 Coffee maker\n",
      "18 0.5082284892974243 Microwave\n",
      "20 0.48645010693452717 Heating\n",
      "19 0.37905077794002323 Refrigerator\n",
      "12 0.16934813891170097 Long term stays allowed\n",
      "23 0.08126649838001963 Private room\n",
      "24 0.06949777947451746 Shared room\n",
      "22 33.99592003815727 Entire home/apt\n",
      "3 13.762520781827684 availability_365\n",
      "0 8.197309303307145 neighbourhood_cleansed\n",
      "10 6.836974394521776 reviews_per_month\n",
      "11 5.930396511853412 host_total_listings_count\n",
      "5 5.700139657313345 bedrooms\n",
      "9 5.0045839020512295 number_of_reviews\n",
      "7 3.3561743333201908 minimum_nights\n",
      "2 3.317112224248663 accommodates\n",
      "8 3.179569574126039 maximum_nights\n",
      "4 2.032566286701684 bathrooms_text\n",
      "21 1.388087250672311 Air conditioning\n",
      "6 1.2564754274587282 beds\n",
      "16 1.0377298198905358 Coffee maker\n",
      "17 1.0248250018190335 Hair dryer\n",
      "18 0.7323558906280873 Microwave\n",
      "20 0.6525965416975583 Heating\n",
      "14 0.6118830348944648 Dishes and silverware\n",
      "19 0.5897055423744899 Refrigerator\n",
      "13 0.5743289823819735 Cooking basics\n",
      "15 0.4507391632002479 Essentials\n",
      "12 0.2492574727891957 Long term stays allowed\n",
      "24 0.0661158988765112 Shared room\n",
      "23 0.052632965888428425 Private room\n",
      "1 0.0 city\n",
      "CPU times: user 1.69 s, sys: 113 ms, total: 1.8 s\n",
      "Wall time: 1.81 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "## Model importances\n",
    "\n",
    "for enum, instance in enumerate(d_dfs.values()):\n",
    "    instance.model_feature_importances(model=l_metrics[enum][\"model\"][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9700a4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "CPU times: user 3.33 s, sys: 243 ms, total: 3.57 s\n",
      "Wall time: 14.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "## Grid Search CV\n",
    "\n",
    "for instance in d_dfs.values():\n",
    "    instance.grid_search_cv_tuning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c706570d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "d_models_resulted = dict()\n",
    "\n",
    "for name,instance in d_dfs.items():\n",
    "    d_models_resulted[name] = instance.return_model_result_gcv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d32e2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
