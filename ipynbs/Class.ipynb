{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "633b15de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "import folium\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from collections import Counter\n",
    "\n",
    "# Modelos\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Métricas\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67785752",
   "metadata": {},
   "outputs": [],
   "source": [
    "class airbnb_city:\n",
    "    \n",
    "    def __init__(self, csvs, city_names):\n",
    "            \n",
    "            self.l_dfs = list()\n",
    "            \n",
    "            for enum, dataset in enumerate(csvs):\n",
    "                \n",
    "                self.l_dfs.append(pd.read_csv(dataset))\n",
    "                \n",
    "                self.l_dfs[enum].drop(\"source\", axis = 1, inplace = True)\n",
    "                \n",
    "                self.l_dfs[enum][\"city\"] = city_names[enum].lower()\n",
    "        \n",
    "            self.df = pd.concat(self.l_dfs)\n",
    "            \n",
    "            print(\"Instance created!\")\n",
    "            \n",
    "    def return_initial_df(self):\n",
    "    \n",
    "        return self.df\n",
    "    \n",
    "    def display__initial_df(self):\n",
    "    \n",
    "        display(self.df)\n",
    "\n",
    "    def clean_tested_columns(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        Sets predefined columns, transforms price to a float column and separates bathroom_text \n",
    "        into 3 different categories, private, shared and unknown.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Sets predefined columns\n",
    "        \n",
    "        tested_cols = ['neighbourhood_cleansed', 'city',\n",
    "                       'room_type', 'accommodates', 'availability_365',\n",
    "                       'bathrooms_text', 'bedrooms', 'beds', 'amenities', 'price',\n",
    "                       'minimum_nights', 'maximum_nights',\n",
    "                       'number_of_reviews', 'reviews_per_month', 'host_total_listings_count']\n",
    "        \n",
    "        self.df_cleaned = self.df[tested_cols]\n",
    "        \n",
    "        # Transforms price to a float column\n",
    "        \n",
    "        self.df_cleaned[\"price\"] = self.df_cleaned[\"price\"].apply(lambda x: float(x.strip(\"$\").replace(',', '')) if pd.notnull(x) else x).values\n",
    "            \n",
    "        # Get numbers out of bathroom_text columns\n",
    "        \n",
    "        self.df_cleaned = self.df_cleaned[self.df_cleaned[\"bathrooms_text\"].isnull() == False]\n",
    "\n",
    "        l_nums = [re.findall(r'\\d+',i) for i in self.df_cleaned[\"bathrooms_text\"].values]\n",
    "\n",
    "        l_nums_completed = []\n",
    "\n",
    "        for i in l_nums:\n",
    "\n",
    "            if len(i) > 1:\n",
    "\n",
    "                l_nums_completed.append('.'.join(i))\n",
    "\n",
    "            elif len(i) == 0:\n",
    "\n",
    "                l_nums_completed.append('0')\n",
    "\n",
    "            else:\n",
    "\n",
    "                l_nums_completed.append(i[0])\n",
    "                \n",
    "        # Create two different columns replacing bathroom_text\n",
    "        \n",
    "        self.df_cleaned[\"bathrooms_text\"] = l_nums_completed\n",
    "\n",
    "        self.df_cleaned[\"bathrooms_text\"] = self.df_cleaned[\"bathrooms_text\"].astype(\"float64\")\n",
    "        \n",
    "        # Amenities\n",
    "        \n",
    "        l_amenities_cleaned, l_amenities_sublisted = list(),list()\n",
    "        \n",
    "        for i in self.df_cleaned[\"amenities\"]:\n",
    "\n",
    "            l_amenities_sublisted.append(json.loads(i))\n",
    "\n",
    "            for j in json.loads(i):\n",
    "\n",
    "                l_amenities_cleaned.append(j)\n",
    "\n",
    "        l_values = list(Counter(l_amenities_cleaned).values())\n",
    "        l_keys = list(Counter(l_amenities_cleaned).keys())\n",
    "\n",
    "        l_valuable_amenities, l_not_relevant_amenities = [], []\n",
    "\n",
    "        for i in l_values:\n",
    "\n",
    "            if i > 10000:\n",
    "\n",
    "                l_valuable_amenities.append(l_keys[l_values.index(i)])\n",
    "\n",
    "            else:\n",
    "\n",
    "                l_not_relevant_amenities.append(l_keys[l_values.index(i)])\n",
    "\n",
    "\n",
    "        l_popular_inter, l_exclusive_inter, l_binary_popular, l_binary_exclusive = [],[],[],[]\n",
    "\n",
    "        popular_amenities = np.array(list(set(l_valuable_amenities)))\n",
    "        exclusive_amenities = np.array(list(set(l_not_relevant_amenities)))\n",
    "\n",
    "        for amenities in l_amenities_sublisted:\n",
    "\n",
    "            l_popular_inter = np.intersect1d(ar1=amenities, ar2= popular_amenities)\n",
    "            l_exclusive_inter = np.intersect1d(ar1=amenities, ar2= exclusive_amenities)\n",
    "\n",
    "            if len(l_popular_inter) > len(amenities)/2:\n",
    "\n",
    "                l_binary_popular.append(1)\n",
    "\n",
    "            else:\n",
    "\n",
    "                l_binary_popular.append(0)\n",
    "\n",
    "            if len(l_exclusive_inter) > len(amenities)/2:\n",
    "\n",
    "                l_binary_exclusive.append(1)\n",
    "\n",
    "            else:\n",
    "\n",
    "                l_binary_exclusive.append(0)\n",
    "\n",
    "        self.df_cleaned[\"popular_amenities\"] = l_binary_popular\n",
    "        self.df_cleaned[\"exclusive_amenities\"] = l_binary_exclusive\n",
    "        self.df_cleaned.drop(\"amenities\", axis = 1, inplace = True)\n",
    "        \n",
    "        \n",
    "###################################################################################################################        \n",
    "#         l_amenities_cleaned = list()\n",
    "        \n",
    "#         for i in self.df_cleaned[\"amenities\"]:\n",
    "\n",
    "#             l_amenities_cleaned.append(json.loads(i))\n",
    "\n",
    "#         # Most relevant amenities, detailed analysis in the EDA file\n",
    "\n",
    "#         l_amenities_valuables = ['Long term stays allowed','Cooking basics','Dishes and silverware','Essentials','Coffee maker','Hair dryer','Microwave','Refrigerator','Heating','Air conditioning']\n",
    "\n",
    "#         for j in l_amenities_valuables:\n",
    "\n",
    "#             self.df_cleaned[j] = [1 if j in i else 0 for i in l_amenities_cleaned]\n",
    "\n",
    "#         self.df_cleaned.drop(\"amenities\", axis =1, inplace=True)\n",
    "        \n",
    "#         self.df_cleaned.dropna(inplace = True)\n",
    "\n",
    "###################################################################################################################\n",
    "        # Room type\n",
    "        \n",
    "        self.df_cleaned = self.df_cleaned[self.df_cleaned[\"room_type\"] != \"Hotel room\"]\n",
    "        self.df_cleaned = pd.concat([self.df_cleaned, pd.get_dummies(data = self.df_cleaned[\"room_type\"])], axis = 1).drop(\"room_type\", axis = 1)\n",
    "        \n",
    "    def return_cleaned(self):\n",
    "        \n",
    "        return self.df_cleaned\n",
    "    \n",
    "    def display_cleaned(self):\n",
    "        \n",
    "        display(self.df_cleaned)\n",
    "    \n",
    "    def remove_outliers(self, accommodates, bathrooms_min, bathrooms_max, bedrooms, beds_min, beds_max, minimum_nights,\n",
    "                       maximum_nights, nreviews, reviews_pmonth, price, htlc):\n",
    "\n",
    "        self.df_cleaned = self.df_cleaned[self.df_cleaned[\"accommodates\"] <= accommodates]\n",
    "        self.df_cleaned = self.df_cleaned[self.df_cleaned[\"bathrooms_text\"].between(bathrooms_min, bathrooms_max)]\n",
    "        self.df_cleaned = self.df_cleaned[self.df_cleaned[\"bedrooms\"] <= bedrooms]\n",
    "        self.df_cleaned = self.df_cleaned[self.df_cleaned[\"beds\"].between(beds_min, beds_max)]\n",
    "        self.df_cleaned = self.df_cleaned[self.df_cleaned[\"minimum_nights\"] <= minimum_nights]\n",
    "        self.df_cleaned = self.df_cleaned[self.df_cleaned[\"maximum_nights\"] <= maximum_nights]\n",
    "        self.df_cleaned = self.df_cleaned[self.df_cleaned[\"number_of_reviews\"] <= nreviews]\n",
    "        self.df_cleaned = self.df_cleaned[self.df_cleaned[\"reviews_per_month\"] <= reviews_pmonth]\n",
    "        self.df_cleaned = self.df_cleaned[self.df_cleaned[\"price\"] <= price]\n",
    "        self.df_cleaned = self.df_cleaned[self.df_cleaned[\"host_total_listings_count\"] <= htlc]\n",
    "\n",
    "        return self.df_cleaned\n",
    "    \n",
    "    def display_outliers(self):\n",
    "        \n",
    "        for i in self.df_cleaned.columns:\n",
    "    \n",
    "            print(i)\n",
    "            sns.kdeplot(self.df_cleaned[i])\n",
    "            plt.show()\n",
    "\n",
    "    def label_encoding(self):\n",
    "        \n",
    "        city_encoder = LabelEncoder()\n",
    "        self.df_cleaned[\"city\"] = city_encoder.fit_transform(self.df_cleaned[\"city\"])\n",
    "        neighbourhood_encoder = LabelEncoder()\n",
    "        self.df_cleaned[\"neighbourhood_cleansed\"] = neighbourhood_encoder.fit_transform(self.df_cleaned[\"neighbourhood_cleansed\"])\n",
    "        \n",
    "        return self.df_cleaned\n",
    "    \n",
    "    def normalize(self):\n",
    "        \n",
    "        x_scaler = MinMaxScaler()\n",
    "        self.df_cleaned[self.df_cleaned.drop(\"price\", axis = 1).columns] = x_scaler.fit_transform(self.df_cleaned[self.df_cleaned.drop(\"price\", axis = 1).columns])\n",
    "\n",
    "        y_scaler = MinMaxScaler()\n",
    "        self.df_cleaned[\"price\"] = y_scaler.fit_transform(self.df_cleaned[[\"price\"]]).flatten()\n",
    "        \n",
    "        return self.df_cleaned\n",
    "    \n",
    "    def tts(self):\n",
    "        \n",
    "        self.X = self.df_cleaned.drop([\"price\"], axis = 1)\n",
    "        self.y = self.df_cleaned[\"price\"]\n",
    "                \n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "        print(f\"X_train: {self.X_train.shape} | y_train: {self.y_train.shape}\")\n",
    "        print(f\"X_test: {self.X_test.shape} | y_test: {self.y_test.shape}\")\n",
    "    \n",
    "    def train_model(self):\n",
    "        \n",
    "        #models = [LinearRegression(), KNeighborsRegressor(), DecisionTreeRegressor(),\n",
    "        #          RandomForestRegressor(), SVR(), AdaBoostRegressor(), GradientBoostingRegressor()]\n",
    "        \n",
    "        \n",
    "        models = [RandomForestRegressor()]\n",
    "        \n",
    "        metrics = list()\n",
    "        \n",
    "        for model in models:\n",
    "            \n",
    "            # fit\n",
    "            \n",
    "            model.fit(self.X_train, self.y_train)\n",
    "\n",
    "            # predict\n",
    "            \n",
    "            self.yhat = model.predict(self.X_test)\n",
    "            \n",
    "            # metrics\n",
    "            \n",
    "            r2 = r2_score(self.y_test, self.yhat)\n",
    "            mse = mean_squared_error(self.y_test, self.yhat)\n",
    "        \n",
    "            metrics.append([str(model), r2, mse, model])\n",
    "            \n",
    "        self.df_metrics = pd.DataFrame(data = metrics, columns = [\"model_name\", \"r2\", \"mse\", \"model\"])\n",
    "        self.df_metrics.sort_values(by = \"r2\", ascending = False, inplace= True)\n",
    "        \n",
    "    def return_metrics(self):\n",
    "        \n",
    "        return self.df_metrics\n",
    "    \n",
    "    def display_metrics(self):\n",
    "        \n",
    "        display(self.df_metrics)\n",
    "        \n",
    "    def model_feature_importances(self, model):\n",
    "        \n",
    "        importances = np.argsort(model.feature_importances_)[::-1]\n",
    "        d_importances = dict()\n",
    "        \n",
    "        for i in importances:\n",
    "\n",
    "            d_importances[i] = [model.feature_importances_[i]*100, self.df_cleaned.drop(\"price\", axis = 1).columns[i]]\n",
    "            print(i, model.feature_importances_[i]*100, self.df_cleaned.drop(\"price\", axis = 1).columns[i])\n",
    "            \n",
    "        return d_importances\n",
    "    \n",
    "    def grid_search_cv_tuning(self):\n",
    "        \n",
    "        model = RandomForestRegressor()\n",
    "        \n",
    "        params = {\"n_estimators\" : [i for i in range(100, 1001, 50)],\n",
    "                  \"max_depth\"    : [8, 10, 12, 14, 16],\n",
    "                  \"max_features\" : [\"log2\", \"sqrt\"]}\n",
    "\n",
    "        scorers = {\"r2\", \"neg_mean_squared_error\"}\n",
    "\n",
    "        grid_solver = GridSearchCV(estimator  = model, \n",
    "                                   param_grid = params, \n",
    "                                   scoring    = scorers,\n",
    "                                   cv         = 10,\n",
    "                                   refit      = \"r2\",\n",
    "                                   n_jobs     = -1, \n",
    "                                   verbose    = 2)\n",
    "\n",
    "        self.model_result = grid_solver.fit(X_train, y_train)\n",
    "        \n",
    "    def grid_search_cv_validation(self):\n",
    "        \n",
    "        l_validations = [self.model_result.best_estimator_,\n",
    "                         self.model_result.cv_results_[\"mean_test_r2\"].max(),\n",
    "                         self.model_result.best_score_]\n",
    "        self.df_validations = pd.DataFrame(data = l_validations, columns = [\"Best Estimator\",\n",
    "                                                                            \"Mean Test R**2\",\n",
    "                                                                            \"Best Score\"])\n",
    "        return self.df_validations\n",
    "    \n",
    "    def final_trial_model(self):\n",
    "        \n",
    "        '''It trains the best model with the features recomended'''\n",
    "        \n",
    "        model = RandomForestRegressor(max_depth=16, max_features='sqrt', n_estimators=650, random_state = 42)\n",
    "        model.fit(self.X_train, self.y_train)\n",
    "        \n",
    "        self.yhat = model.predict(self.X_test)\n",
    "    \n",
    "        return f\"r**2 = {r2_score(self.y_test, self.yhat)}\"\n",
    "    \n",
    "    def train_final_model(self, max_depth, max_features, n_estimators,random_state):\n",
    "        \n",
    "        '''Returns the definitive model'''\n",
    "        \n",
    "        self.X_def = self.df_cleaned.drop([\"price\"], axis = 1)\n",
    "        self.y_def = self.df_cleaned[\"price\"]\n",
    "        \n",
    "        model = RandomForestRegressor(max_depth = max_depth, max_features = max_features, n_estimators = n_estimators, random_state = random_state)\n",
    "        model.fit(self.X_def, self.y_def)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def predict(self, array):  \n",
    "        \n",
    "        '''Predicts the price given a cleaned array with te features needed'''\n",
    "        \n",
    "        price_predicted = y_scaler.inverse_transform([model.predict([array])])\n",
    "        \n",
    "        return price_predicted\n",
    "    \n",
    "    def save_model(self, name, ext, model):\n",
    "    \n",
    "        with open(f\"{name}.{ext}\", \"wb\") as file:\n",
    "            pickle.dump(model)\n",
    "            \n",
    "    def load_model(self, name, ext):\n",
    "        \n",
    "        with open(f\"{name}.{ext}\", \"rb\") as file:\n",
    "            self.model = pickle.load(file)\n",
    "            \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5cbde06",
   "metadata": {},
   "outputs": [],
   "source": [
    "madrid = \"datasets/madrid.csv\"\n",
    "rome = \"datasets/rome.csv\"\n",
    "paris = \"datasets/paris.csv\"\n",
    "oslo = \"datasets/oslo.csv\"\n",
    "london = \"datasets/london.csv\"\n",
    "geneva = \"datasets/geneva.csv\"\n",
    "dublin = \"datasets/dublin.csv\"\n",
    "barcelona = \"datasets/barcelona.csv\"\n",
    "athens = \"datasets/athens.csv\"\n",
    "amsterdam = \"datasets/amsterdam.csv\"\n",
    "\n",
    "d_csvs, d_names = dict(), dict()\n",
    "\n",
    "d_csvs[\"csvs1\"] = [madrid, barcelona]\n",
    "# d_csvs[\"csvs2\"] = [madrid, barcelona, london]\n",
    "# d_csvs[\"csvs3\"] = [madrid, barcelona, london, paris]\n",
    "# d_csvs[\"csvs4\"] = [madrid, barcelona, london, paris, dublin]\n",
    "# d_csvs[\"csvs5\"] = [madrid, barcelona, london, paris, dublin, rome]\n",
    "# d_csvs[\"csvs6\"] = [madrid, barcelona, london, paris, dublin, rome, amsterdam]\n",
    "# d_csvs[\"csvs7\"] = [madrid, barcelona,london, paris, dublin, rome, amsterdam, athens]\n",
    "# d_csvs[\"csvs8\"] = [madrid, barcelona,london, paris, dublin, rome, amsterdam, athens, oslo]\n",
    "# d_csvs[\"csvs9\"] = [madrid, barcelona,london, paris, dublin, rome, amsterdam, athens, oslo, geneva]\n",
    "d_csvs[\"csvs2\"] = [madrid, barcelona, paris, london, amsterdam, rome, dublin, geneva, athens, oslo]\n",
    "\n",
    "d_names[\"names1\"] = [\"madrid\", \"barcelona\"]\n",
    "# d_names[\"names2\"] = [\"madrid\", \"barcelona\",\"london\"]\n",
    "# d_names[\"names3\"] = [\"madrid\", \"barcelona\",\"london\", \"paris\"]\n",
    "# d_names[\"names4\"] = [\"madrid\", \"barcelona\",\"london\", \"paris\", \"dublin\"]\n",
    "# d_names[\"names5\"] = [\"madrid\", \"barcelona\",\"london\", \"paris\", \"dublin\", \"rome\"]\n",
    "# d_names[\"names6\"] = [\"madrid\", \"barcelona\",\"london\", \"paris\", \"dublin\", \"rome\", \"amsterdam\"]\n",
    "# d_names[\"names7\"] = [\"madrid\", \"barcelona\",\"london\", \"paris\", \"dublin\", \"rome\", \"amsterdam\", \"athens\"]\n",
    "# d_names[\"names8\"] = [\"madrid\", \"barcelona\",\"london\", \"paris\", \"dublin\", \"rome\", \"amsterdam\", \"athens\", \"oslo\"]\n",
    "# d_names[\"names9\"] = [\"madrid\", \"barcelona\",\"london\", \"paris\", \"dublin\", \"rome\", \"amsterdam\", \"athens\", \"oslo\", \"geneva\"]\n",
    "d_names[\"names2\"] = [\"madrid\", \"barcelona\",\"paris\", \"london\", \"amsterdam\", \"rome\",\"dublin\",\"geneva\",\"athens\",\"oslo\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab4807ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_dfs = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c6ab1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance created!\n",
      "Instance created!\n",
      "CPU times: user 6.75 s, sys: 618 ms, total: 7.37 s\n",
      "Wall time: 7.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for i in range(1,3):\n",
    "    \n",
    "    d_dfs[f\"instance{i}\"] = airbnb_city(d_csvs[f\"csvs{i}\"],d_names[f\"names{i}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa091557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([<__main__.airbnb_city object at 0x7fc79099f220>, <__main__.airbnb_city object at 0x7fc798c72c40>])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_dfs.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05c8dff0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/10/5nbnv2696vlgb605wf3g6wwh0000gn/T/ipykernel_5322/4162281428.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.df_cleaned[\"price\"] = self.df_cleaned[\"price\"].apply(lambda x: float(x.strip(\"$\").replace(',', '')) if pd.notnull(x) else x).values\n",
      "/var/folders/10/5nbnv2696vlgb605wf3g6wwh0000gn/T/ipykernel_5322/4162281428.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.df_cleaned[\"price\"] = self.df_cleaned[\"price\"].apply(lambda x: float(x.strip(\"$\").replace(',', '')) if pd.notnull(x) else x).values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39.4 s, sys: 1.14 s, total: 40.6 s\n",
      "Wall time: 40.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for instance in d_dfs.values():\n",
    "    \n",
    "    instance.clean_tested_columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca73be18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6 µs, sys: 4 µs, total: 10 µs\n",
      "Wall time: 11 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "l_dfs = list()\n",
    "\n",
    "for instance in d_dfs.values():\n",
    "    \n",
    "    l_dfs.append(instance.return_cleaned())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09199853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 106 ms, sys: 35 ms, total: 141 ms\n",
      "Wall time: 148 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for instance in d_dfs.values():\n",
    "    \n",
    "    instance.remove_outliers(accommodates=8,\n",
    "                             bathrooms_min=1,\n",
    "                             bathrooms_max=2,\n",
    "                             bedrooms=4,\n",
    "                             beds_min=1,\n",
    "                             beds_max=5,\n",
    "                             minimum_nights=30,\n",
    "                             maximum_nights=500000,\n",
    "                             nreviews=300,\n",
    "                             reviews_pmonth=8,\n",
    "                             price=400,\n",
    "                             htlc=500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8df6095b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neighbourhood_cleansed</th>\n",
       "      <th>city</th>\n",
       "      <th>accommodates</th>\n",
       "      <th>availability_365</th>\n",
       "      <th>bathrooms_text</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>maximum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>host_total_listings_count</th>\n",
       "      <th>popular_amenities</th>\n",
       "      <th>exclusive_amenities</th>\n",
       "      <th>Entire home/apt</th>\n",
       "      <th>Private room</th>\n",
       "      <th>Shared room</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hispanoamérica</td>\n",
       "      <td>madrid</td>\n",
       "      <td>2</td>\n",
       "      <td>56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1125</td>\n",
       "      <td>99</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cármenes</td>\n",
       "      <td>madrid</td>\n",
       "      <td>1</td>\n",
       "      <td>255</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>33</td>\n",
       "      <td>0.34</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Legazpi</td>\n",
       "      <td>madrid</td>\n",
       "      <td>1</td>\n",
       "      <td>339</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1125</td>\n",
       "      <td>166</td>\n",
       "      <td>1.10</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sol</td>\n",
       "      <td>madrid</td>\n",
       "      <td>2</td>\n",
       "      <td>353</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>5</td>\n",
       "      <td>180</td>\n",
       "      <td>171</td>\n",
       "      <td>1.15</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Embajadores</td>\n",
       "      <td>madrid</td>\n",
       "      <td>1</td>\n",
       "      <td>287</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1124</td>\n",
       "      <td>6</td>\n",
       "      <td>0.05</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4203</th>\n",
       "      <td>Søndre Nordstrand</td>\n",
       "      <td>oslo</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>370.0</td>\n",
       "      <td>1</td>\n",
       "      <td>365</td>\n",
       "      <td>4</td>\n",
       "      <td>1.15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4637</th>\n",
       "      <td>Alna</td>\n",
       "      <td>oslo</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>15</td>\n",
       "      <td>365</td>\n",
       "      <td>3</td>\n",
       "      <td>1.45</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4718</th>\n",
       "      <td>St. Hanshaugen</td>\n",
       "      <td>oslo</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>30</td>\n",
       "      <td>365</td>\n",
       "      <td>7</td>\n",
       "      <td>3.23</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4810</th>\n",
       "      <td>Gamle Oslo</td>\n",
       "      <td>oslo</td>\n",
       "      <td>1</td>\n",
       "      <td>316</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>383.0</td>\n",
       "      <td>1</td>\n",
       "      <td>365</td>\n",
       "      <td>12</td>\n",
       "      <td>6.10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5099</th>\n",
       "      <td>Alna</td>\n",
       "      <td>oslo</td>\n",
       "      <td>2</td>\n",
       "      <td>234</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1125</td>\n",
       "      <td>1</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>131126 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     neighbourhood_cleansed    city  accommodates  availability_365  \\\n",
       "0            Hispanoamérica  madrid             2                56   \n",
       "1                  Cármenes  madrid             1               255   \n",
       "3                   Legazpi  madrid             1               339   \n",
       "5                       Sol  madrid             2               353   \n",
       "6               Embajadores  madrid             1               287   \n",
       "...                     ...     ...           ...               ...   \n",
       "4203      Søndre Nordstrand    oslo             2                 0   \n",
       "4637                   Alna    oslo             1                 6   \n",
       "4718         St. Hanshaugen    oslo             2                23   \n",
       "4810             Gamle Oslo    oslo             1               316   \n",
       "5099                   Alna    oslo             2               234   \n",
       "\n",
       "      bathrooms_text  bedrooms  beds  price  minimum_nights  maximum_nights  \\\n",
       "0                1.0       1.0   1.0   77.0               3            1125   \n",
       "1                1.0       1.0   1.0   31.0               4              40   \n",
       "3                1.0       1.0   1.0   26.0               2            1125   \n",
       "5                1.0       1.0   2.0  120.0               5             180   \n",
       "6                1.0       1.0   1.0   20.0               6            1124   \n",
       "...              ...       ...   ...    ...             ...             ...   \n",
       "4203             1.5       1.0   2.0  370.0               1             365   \n",
       "4637             1.0       1.0   1.0  400.0              15             365   \n",
       "4718             1.0       1.0   1.0  400.0              30             365   \n",
       "4810             1.0       1.0   2.0  383.0               1             365   \n",
       "5099             1.0       1.0   1.0  400.0               1            1125   \n",
       "\n",
       "      number_of_reviews  reviews_per_month  host_total_listings_count  \\\n",
       "0                    99               0.65                        1.0   \n",
       "1                    33               0.34                        2.0   \n",
       "3                   166               1.10                        4.0   \n",
       "5                   171               1.15                        6.0   \n",
       "6                     6               0.05                       19.0   \n",
       "...                 ...                ...                        ...   \n",
       "4203                  4               1.15                        1.0   \n",
       "4637                  3               1.45                        3.0   \n",
       "4718                  7               3.23                        2.0   \n",
       "4810                 12               6.10                        2.0   \n",
       "5099                  1               0.81                        1.0   \n",
       "\n",
       "      popular_amenities  exclusive_amenities  Entire home/apt  Private room  \\\n",
       "0                     1                    0                0             1   \n",
       "1                     1                    0                0             1   \n",
       "3                     1                    0                0             1   \n",
       "5                     1                    0                1             0   \n",
       "6                     1                    0                0             1   \n",
       "...                 ...                  ...              ...           ...   \n",
       "4203                  1                    0                0             1   \n",
       "4637                  1                    0                0             1   \n",
       "4718                  1                    0                0             1   \n",
       "4810                  1                    0                0             1   \n",
       "5099                  1                    0                0             1   \n",
       "\n",
       "      Shared room  \n",
       "0               0  \n",
       "1               0  \n",
       "3               0  \n",
       "5               0  \n",
       "6               0  \n",
       "...           ...  \n",
       "4203            0  \n",
       "4637            0  \n",
       "4718            0  \n",
       "4810            0  \n",
       "5099            0  \n",
       "\n",
       "[131126 rows x 18 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_dfs[\"instance2\"].return_cleaned()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca68b624",
   "metadata": {},
   "outputs": [],
   "source": [
    "for instance in d_dfs.values():\n",
    "    instance.label_encoding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb3a2872",
   "metadata": {},
   "outputs": [],
   "source": [
    "for instance in d_dfs.values():\n",
    "    instance.normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce7c622d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (16675, 17) | y_train: (16675,)\n",
      "X_test: (4169, 17) | y_test: (4169,)\n",
      "X_train: (104900, 17) | y_train: (104900,)\n",
      "X_test: (26226, 17) | y_test: (26226,)\n"
     ]
    }
   ],
   "source": [
    "for instance in d_dfs.values():\n",
    "    instance.tts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef32826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>r2</th>\n",
       "      <th>mse</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestRegressor()</td>\n",
       "      <td>0.706963</td>\n",
       "      <td>0.011671</td>\n",
       "      <td>(DecisionTreeRegressor(max_features='auto', ra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model_name        r2       mse  \\\n",
       "0  RandomForestRegressor()  0.706963  0.011671   \n",
       "\n",
       "                                               model  \n",
       "0  (DecisionTreeRegressor(max_features='auto', ra...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for instance in d_dfs.values():\n",
    "    \n",
    "    instance.train_model()\n",
    "    instance.display_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f7c4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "adsfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2298b249",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "d_scores_ft = dict()\n",
    "\n",
    "for name, instance in d_dfs.items():\n",
    "    \n",
    "    d_scores_ft[name] = instance.final_trial_model()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9fd8d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ae6c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_scores_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d531bf91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
