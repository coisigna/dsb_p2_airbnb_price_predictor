{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633b15de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "import folium\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "# Modelos\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# MÃ©tricas\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67785752",
   "metadata": {},
   "outputs": [],
   "source": [
    "class airbnb_city:\n",
    "    \n",
    "    def __init__(self, csvs, city_names):\n",
    "        \n",
    "        if type(csvs) != list:\n",
    "            \n",
    "            self.csv = csv\n",
    "\n",
    "            self.df = pd.read_csv(self.csv)\n",
    "            \n",
    "            self.df[\"city\"] = city_names\n",
    "            \n",
    "            print(\"Instance created!\")\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            for enum, dataset in enumerate(csvs):\n",
    "    \n",
    "                dataset.drop(\"source\", axis = 1, inplace = True)\n",
    "                \n",
    "                dataset[\"city\"] = city_names[enum].lower()\n",
    "        \n",
    "            self.df = pd.concat(csvs)\n",
    "            \n",
    "            print(\"Instance created!\")\n",
    "            \n",
    "    def return_initial_df(self):\n",
    "    \n",
    "        return self.df\n",
    "    \n",
    "    def display__initial_df(self):\n",
    "    \n",
    "        display(self.df)\n",
    "\n",
    "    def clean_tested_columns(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        Sets predefined columns, transforms price to a float column and separates bathroom_text \n",
    "        into 3 different categories, private, shared and unknown.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Sets predefined columns\n",
    "        \n",
    "        tested_cols = ['neighbourhood_cleansed', 'city',\n",
    "                       'room_type', 'accommodates',\n",
    "                       'bathrooms_text', 'bedrooms', 'beds', 'amenities', 'price',\n",
    "                       'minimum_nights', 'maximum_nights', 'availability_365',\n",
    "                       'number_of_reviews', 'reviews_per_month', 'host_total_listings_count']\n",
    "        \n",
    "        self.df_cleaned = self.df[tested_cols]\n",
    "        \n",
    "        # Transforms price to a float column\n",
    "        \n",
    "        self.df_cleaned[\"price\"] = self.df_cleaned[\"price\"].apply(lambda x: float(x.strip(\"$\").replace(',', '')) if pd.notnull(x) else x).values\n",
    "            \n",
    "        # Get numbers out of bathroom_text columns\n",
    "        \n",
    "        self.df_cleaned = self.df_cleaned[self.df_cleaned[\"bathrooms_text\"].isnull() == False]\n",
    "\n",
    "        l_nums = [re.findall(r'\\d+',i) for i in self.df_cleaned[\"bathrooms_text\"].values]\n",
    "\n",
    "        l_nums_completed = []\n",
    "\n",
    "        for i in l_nums:\n",
    "\n",
    "            if len(i) > 1:\n",
    "\n",
    "                l_nums_completed.append('.'.join(i))\n",
    "\n",
    "            elif len(i) == 0:\n",
    "\n",
    "                l_nums_completed.append('0')\n",
    "\n",
    "            else:\n",
    "\n",
    "                l_nums_completed.append(i[0])\n",
    "                \n",
    "        # Create two different columns replacing bathroom_text\n",
    "        \n",
    "        self.df_cleaned[\"bathrooms_text\"] = l_nums_completed\n",
    "\n",
    "        self.df_cleaned[\"bathrooms_text\"] = self.df_cleaned[\"bathrooms_text\"].astype(\"float64\")\n",
    "        \n",
    "        # Amenities\n",
    "        \n",
    "        l_amenities_cleaned = list()\n",
    "        \n",
    "        for i in self.df_cleaned[\"amenities\"]:\n",
    "\n",
    "            l_amenities_cleaned.append(json.loads(i))\n",
    "\n",
    "        # Most relevant amenities, detailed analysis in the EDA file\n",
    "\n",
    "        l_amenities_valuables = ['Long term stays allowed','Cooking basics','Dishes and silverware','Essentials','Coffee maker','Hair dryer','Microwave','Refrigerator','Heating','Air conditioning']\n",
    "\n",
    "        for j in l_amenities_valuables:\n",
    "\n",
    "            self.df_cleaned[j] = [1 if j in i else 0 for i in l_amenities_cleaned]\n",
    "\n",
    "        self.df_cleaned.drop(\"amenities\", axis =1, inplace=True)\n",
    "        \n",
    "        self.df_cleaned.dropna(inplace = True)\n",
    "        \n",
    "        # Room type\n",
    "        \n",
    "        self.df_cleaned = self.df_cleaned[self.df_cleaned[\"room_type\"] != \"Hotel room\"]\n",
    "        self.df_cleaned = pd.concat([self.df_cleaned, pd.get_dummies(data = self.df_cleaned[\"room_type\"])], axis = 1).drop(\"room_type\", axis = 1)\n",
    "        \n",
    "        return self.df_cleaned\n",
    "        \n",
    "    def label_encoding(self):\n",
    "        \n",
    "        city_encoder = LabelEncoder()\n",
    "        self.df_cleaned[\"city\"] = city_encoder.fit_transform(self.df_cleaned[\"city\"])\n",
    "        neighbourhood_encoder = LabelEncoder()\n",
    "        self.df_cleaned[\"neighbourhood_cleansed\"] = neighbourhood_encoder.fit_transform(self.df_cleaned[\"neighbourhood_cleansed\"])\n",
    "        \n",
    "        return self.df_cleaned\n",
    "    \n",
    "    def remove_outliers(self, accommodates, bathrooms_min, bathrooms_max, bedrooms, beds_min, beds_max, minimum_nights,\n",
    "                       maximum_nights, nreviews, reviews_pmonth, price, htlc):\n",
    "\n",
    "        self.df_cleaned = self.df_cleaned[self.df_cleaned[\"accommodates\"] <= accommodates]\n",
    "        self.df_cleaned = self.df_cleaned[self.df_cleaned[\"bathrooms_text\"].between(bathrooms_min, bathrooms_max)]\n",
    "        self.df_cleaned = self.df_cleaned[self.df_cleaned[\"bedrooms\"] <= bedrooms]\n",
    "        self.df_cleaned = self.df_cleaned[self.df_cleaned[\"beds\"].between(beds_min, beds_max)]\n",
    "        self.df_cleaned = self.df_cleaned[self.df_cleaned[\"minimum_nights\"] <= minimum_nights]\n",
    "        self.df_cleaned = self.df_cleaned[self.df_cleaned[\"maximum_nights\"] <= maximum_nights]\n",
    "        self.df_cleaned = self.df_cleaned[self.df_cleaned[\"number_of_reviews\"] <= nreviews]\n",
    "        self.df_cleaned = self.df_cleaned[self.df_cleaned[\"reviews_per_month\"] <= reviews_pmonth]\n",
    "        self.df_cleaned = self.df_cleaned[self.df_cleaned[\"price\"] <= price]\n",
    "        self.df_cleaned = self.df_cleaned[self.df_cleaned[\"host_total_listings_count\"] <= htlc]\n",
    "\n",
    "        return self.df_cleaned\n",
    "\n",
    "    def normalize(self):\n",
    "        \n",
    "        x_scaler = MinMaxScaler()\n",
    "        self.df_cleaned[self.df_cleaned.drop(\"price\", axis = 1).columns] = x_scaler.fit_transform(self.df_cleaned[self.df_cleaned.drop(\"price\", axis = 1).columns])\n",
    "\n",
    "        y_scaler = MinMaxScaler()\n",
    "        self.df_cleaned[\"price\"] = y_scaler.fit_transform(self.df_cleaned[[\"price\"]]).flatten()\n",
    "        \n",
    "        return self.df_cleaned\n",
    "    \n",
    "    def tts(self):\n",
    "        \n",
    "        self.X = self.df_cleaned.drop([\"price\"], axis = 1)\n",
    "        self.y = self.df_cleaned[\"price\"]\n",
    "                \n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.X, self.y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "        print(f\"X_train: {self.X_train.shape} | y_train: {self.y_train.shape}\")\n",
    "        print(f\"X_test: {self.X_test.shape} | y_test: {self.y_test.shape}\")\n",
    "    \n",
    "    def train_model(self):\n",
    "        \n",
    "        models = [LinearRegression(), KNeighborsRegressor(), DecisionTreeRegressor(),\n",
    "                  RandomForestRegressor(), SVR(), AdaBoostRegressor(), GradientBoostingRegressor()]\n",
    "        \n",
    "        metrics = list()\n",
    "        \n",
    "        for model in models:\n",
    "            \n",
    "            # fit\n",
    "            \n",
    "            model.fit(self.X_train, self.y_train)\n",
    "\n",
    "            # predict\n",
    "            \n",
    "            self.yhat = model.predict(self.X_test)\n",
    "            \n",
    "            # metrics\n",
    "            \n",
    "            r2 = r2_score(self.y_test, self.yhat)\n",
    "            mse = mean_squared_error(self.y_test, self.yhat)\n",
    "        \n",
    "            metrics.append([str(model), r2, mse, model])\n",
    "            \n",
    "        self.df_metrics = pd.DataFrame(data = metrics, columns = [\"model_name\", \"r2\", \"mse\", \"model\"])\n",
    "        self.df_metrics.sort_values(by = \"r2\", ascending = False, inplace= True)\n",
    "        \n",
    "    def return_metrics(self):\n",
    "        \n",
    "        return self.df_metrics\n",
    "    \n",
    "    def display_metrics(self):\n",
    "        \n",
    "        display(self.df_metrics)\n",
    "        \n",
    "    def model_feature_importances(self, model):\n",
    "        \n",
    "        importances = np.argsort(model.feature_importances_)[::-1]\n",
    "        d_importances = dict()\n",
    "        \n",
    "        for i in importances:\n",
    "\n",
    "            d_importances[i] = [model.feature_importances_[i]*100, self.df_cleaned.drop(\"price\", axis = 1).columns[i]]\n",
    "            print(i, model.feature_importances_[i]*100, self.df_cleaned.drop(\"price\", axis = 1).columns[i])\n",
    "            \n",
    "        return d_importances\n",
    "    \n",
    "    def grid_search_cv_tuning(self):\n",
    "        \n",
    "        model = RandomForestRegressor()\n",
    "        \n",
    "        params = {\"n_estimators\" : [i for i in range(100, 1001, 50)],\n",
    "                  \"max_depth\"    : [8, 10, 12, 14, 16],\n",
    "                  \"max_features\" : [\"log2\", \"sqrt\"]}\n",
    "\n",
    "        scorers = {\"r2\", \"neg_mean_squared_error\"}\n",
    "\n",
    "        grid_solver = GridSearchCV(estimator  = model, \n",
    "                                   param_grid = params, \n",
    "                                   scoring    = scorers,\n",
    "                                   cv         = 10,\n",
    "                                   refit      = \"r2\",\n",
    "                                   n_jobs     = -1, \n",
    "                                   verbose    = 2)\n",
    "\n",
    "        self.model_result = grid_solver.fit(X_train, y_train)\n",
    "        \n",
    "    def grid_search_cv_validation(self):\n",
    "        \n",
    "        l_validations = [self.model_result.best_estimator_,\n",
    "                         self.model_result.cv_results_[\"mean_test_r2\"].max(),\n",
    "                         self.model_result.best_score_]\n",
    "        self.df_validations = pd.DataFrame(data = l_validations, columns = [\"Best Estimator\",\n",
    "                                                                            \"Mean Test R**2\",\n",
    "                                                                            \"Best Score\"])\n",
    "        return self.df_validations\n",
    "    \n",
    "    def save_model(self, name, ext, model)\n",
    "    \n",
    "        with open(f\"{name}.{ext}\", \"wb\") as file:\n",
    "            pickle.dump(model)\n",
    "            \n",
    "    def load_model(self, name, ext):\n",
    "        \n",
    "        with open(f\"{name}.{ext}\", \"rb\") as file:\n",
    "            self.model = pickle.load(file)\n",
    "            \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cbde06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_madrid = \"madrid\"\n",
    "df_rome = \"rome\"\n",
    "df_paris = \"paris\"\n",
    "df_oslo = \"oslo\"\n",
    "df_london = \"london\"\n",
    "df_geneva = \"geneva\"\n",
    "df_dublin = \"dublin\"\n",
    "df_barcelona = \"barcelona\"\n",
    "df_athens = \"athens\"\n",
    "df_amsterdam = \"amsterdam\"\n",
    "\n",
    "\n",
    "df_madrid[\"city\"] = \"madrid\"\n",
    "df_rome[\"city\"] = \"rome\"\n",
    "df_paris[\"city\"] = \"paris\"\n",
    "df_oslo[\"city\"] = \"oslo\"\n",
    "df_london[\"city\"] = \"london\"\n",
    "df_geneva[\"city\"] = \"geneva\"\n",
    "df_dublin[\"city\"] = \"dublin\"\n",
    "df_barcelona[\"city\"] = \"barcelona\"\n",
    "df_athens[\"city\"] = \"athens\"\n",
    "df_amsterdam[\"city\"] = \"amsterdam\"\n",
    "\n",
    "\n",
    "#l_coms = [df_madrid,df_barcelona,df_paris,df_london,df_milan,df_rome,df_geneva]\n",
    "l_coms = [df_madrid, \n",
    "          df_barcelona]\n",
    "\"\"\",\n",
    "          df_paris,\n",
    "          df_london,\n",
    "          df_amsterdam,\n",
    "          df_rome,\n",
    "          df_dublin,\n",
    "          df_geneva,\n",
    "          df_athens,\n",
    "          df_oslo]\n",
    "\"\"\"\n",
    "\n",
    "l_names = [\"Madrid\",\"Barcelona\"]#,\"Paris\",\"London\",\"Amsterdam\",\"Rome\",\"Dublin\",\"Geneva\",\"Athens\",\"Oslo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361d857e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = airbnb_city(l_coms,l_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb440f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = df.clean_tested_columns()\n",
    "\n",
    "\n",
    "df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09199853",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.remove_outliers(accommodates=8,\n",
    "                   bathrooms_min=1,\n",
    "                   bathrooms_max=2,\n",
    "                   bedrooms=4,\n",
    "                   beds_min=1,\n",
    "                   beds_max=5,\n",
    "                   minimum_nights=30,\n",
    "                   maximum_nights=500000,\n",
    "                   nreviews=300,\n",
    "                   reviews_pmonth=8,\n",
    "                   price=400,\n",
    "                   htlc=500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca68b624",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.label_encoding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3a2872",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7c622d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2298b249",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99f4b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = df.return_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c0d850",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.display_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3508ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = metrics[\"model\"][3]\n",
    "d_fi = df.model_feature_importances(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829f2860",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af32f21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
