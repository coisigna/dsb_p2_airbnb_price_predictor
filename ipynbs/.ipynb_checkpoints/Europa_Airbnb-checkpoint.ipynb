{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14c82521",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b808e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_madrid = pd.read_csv(\"madrid.csv\")\n",
    "df_rome = pd.read_csv(\"rome.csv\")\n",
    "df_paris = pd.read_csv(\"paris.csv\")\n",
    "df_oslo = pd.read_csv(\"oslo.csv\")\n",
    "df_london = pd.read_csv(\"london.csv\")\n",
    "df_geneva = pd.read_csv(\"geneva.csv\")\n",
    "df_dublin = pd.read_csv(\"dublin.csv\")\n",
    "df_barcelona = pd.read_csv(\"barcelona.csv\")\n",
    "df_athens = pd.read_csv(\"athens.csv\")\n",
    "df_amsterdam = pd.read_csv(\"amsterdam.csv\")\n",
    "\n",
    "\n",
    "l_dataframes = [df_madrid, df_barcelona, df_rome, df_paris, df_oslo, df_london, df_geneva, df_dublin, df_athens, df_amsterdam]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2586823",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in l_dataframes:\n",
    "    i.drop(\"source\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fa2a4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat(l_dataframes)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109b899e",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_columns_chosen = ['id', 'neighbourhood_cleansed',\n",
    "                    'room_type', 'accommodates',\n",
    "                    'bathrooms_text', 'bedrooms', 'beds', 'amenities', 'price',\n",
    "                    'minimum_nights', 'maximum_nights', 'availability_365',\n",
    "                    'number_of_reviews', 'reviews_per_month', 'host_total_listings_count']\n",
    "df = df[l_columns_chosen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23081a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()/df.shape[0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47859411",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"bathrooms_text\"] = df[\"bathrooms_text\"].apply(lambda x : x.split(\" \")[0] if (type(x) == str) and (\"bath\" in x) else np.nan)\n",
    "\n",
    "bath_map = {\"Private\" : 1, \"Shared\" : 0.5, \"Half-bath\" : 0.5}\n",
    "\n",
    "df[\"bathrooms_text\"] = df[\"bathrooms_text\"].apply(lambda x : bath_map[x] if x in bath_map.keys() else float(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c60904d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# amenities: nÃºmero de elementos en la lista\n",
    "\n",
    "list_amenities = list()\n",
    "\n",
    "for num, x in enumerate(df[\"amenities\"].values):\n",
    "    try:\n",
    "        list_amenities.append(len(json.loads((x.replace(\"'\", '\"')))))\n",
    "        \n",
    "    except:\n",
    "        list_amenities.append(len(x.replace(\"'\", '\"').replace(\"\\\\\", \"\")))\n",
    "        \n",
    "        \n",
    "df[\"amenities\"] = list_amenities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e76c01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import json\n",
    "from collections import Counter\n",
    "l_amenities_cleaned, l_amenities_sublisted = list(),list()\n",
    "for i in df[\"amenities\"]:\n",
    "    \n",
    "    l_amenities_sublisted.append(json.loads(i))\n",
    "    \n",
    "    for j in json.loads(i):\n",
    "    \n",
    "        l_amenities_cleaned.append(j)\n",
    "\n",
    "l_values = list(Counter(l_amenities_cleaned).values())\n",
    "l_keys = list(Counter(l_amenities_cleaned).keys())\n",
    "\n",
    "l_valuable_amenities, l_not_relevant_amenities = [], []\n",
    "\n",
    "for i in l_values:\n",
    "    \n",
    "    if i > 10000:\n",
    "        \n",
    "        l_valuable_amenities.append(l_keys[l_values.index(i)])\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        l_not_relevant_amenities.append(l_keys[l_values.index(i)])\n",
    "        \n",
    "cont = 0\n",
    "l_popular, l_exclusive = [],[]\n",
    "\n",
    "for i in l_amenities_sublisted:\n",
    "    \n",
    "    for j in l_valuable_amenities:\n",
    "        \n",
    "        if j in i:\n",
    "            \n",
    "            cont+=1\n",
    "        \n",
    "    if cont > len(i)/2:\n",
    "\n",
    "        l_popular.append(1)\n",
    "\n",
    "    else:\n",
    "\n",
    "        l_popular.append(0)\n",
    "\n",
    "    cont = 0\n",
    "        \n",
    "    for k in l_not_relevant_amenities:\n",
    "        \n",
    "        if k in i:\n",
    "            \n",
    "            cont += 1\n",
    "            \n",
    "    if cont > len(i)/2:\n",
    "\n",
    "        l_exclusive.append(1)\n",
    "\n",
    "    else:\n",
    "\n",
    "        l_exclusive.append(0)\n",
    "            \n",
    "    cont = 0\n",
    "    \n",
    "df[\"popular_amenities\"] = l_popular\n",
    "df[\"exclusive_amenities\"] = l_exclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11ef0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import json\n",
    "from collections import Counter\n",
    "l_amenities_cleaned, l_amenities_sublisted = list(),list()\n",
    "for i in df[\"amenities\"]:\n",
    "    \n",
    "    l_amenities_sublisted.append(json.loads(i))\n",
    "    \n",
    "    for j in json.loads(i):\n",
    "    \n",
    "        l_amenities_cleaned.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60eb353a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "l_values = list(Counter(l_amenities_cleaned).values())\n",
    "l_keys = list(Counter(l_amenities_cleaned).keys())\n",
    "\n",
    "l_valuable_amenities, l_not_relevant_amenities = [], []\n",
    "\n",
    "for i in l_values:\n",
    "    \n",
    "    if i > 10000:\n",
    "        \n",
    "        l_valuable_amenities.append(l_keys[l_values.index(i)])\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        l_not_relevant_amenities.append(l_keys[l_values.index(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3f3c2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7043e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont = 0\n",
    "l_popular, l_exclusive = [],[]\n",
    "\n",
    "for i in l_amenities_sublisted:\n",
    "    \n",
    "    for j in l_valuable_amenities:\n",
    "        \n",
    "        if j in i:\n",
    "            \n",
    "            cont+=1\n",
    "        \n",
    "    if cont > len(i)/2:\n",
    "\n",
    "        l_popular.append(1)\n",
    "\n",
    "    else:\n",
    "\n",
    "        l_popular.append(0)\n",
    "\n",
    "    cont = 0\n",
    "        \n",
    "    for k in l_not_relevant_amenities:\n",
    "        \n",
    "        if k in i:\n",
    "            \n",
    "            cont += 1\n",
    "            \n",
    "    if cont > len(i)/2:\n",
    "\n",
    "        l_exclusive.append(1)\n",
    "\n",
    "    else:\n",
    "\n",
    "        l_exclusive.append(0)\n",
    "            \n",
    "    cont = 0\n",
    "    \n",
    "df[\"popular_amenities\"] = l_popular\n",
    "df[\"exclusive_amenities\"] = l_exclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5adc1af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92b6d00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0676fb64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f782ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d43c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.drop(\"amenities\", axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96b934b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396ff4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"price\"] = df[\"price\"].apply(lambda x: float(x.strip(\"$\").replace(',', '')) if pd.notnull(x) else x).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4beec4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0380f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num = df._get_numeric_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c51e006",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat = df.drop(df_num.columns, axis = 1)\n",
    "df_cat = pd.concat([df_cat, df_num[[\"id\"]]], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ab4a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# room_type: eliminar \"Hotel room\" y transformar a dummies\n",
    "\n",
    "df_cat = df_cat[df_cat[\"room_type\"] != \"Hotel room\"]\n",
    "\n",
    "df_cat = pd.concat([df_cat, pd.get_dummies(data = df_cat[\"room_type\"])], axis = 1).drop(\"room_type\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2e3a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uso el LabelEncoder para transformarlo a nÃºmeros sin ningÃºn tipo de relaciÃ³n u orden\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "neighbourhood_encoder = LabelEncoder()\n",
    "df_cat[\"neighbourhood_cleansed\"] = neighbourhood_encoder.fit_transform(df_cat[\"neighbourhood_cleansed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9623125a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uso el LabelEncoder para transformarlo a nÃºmeros sin ningÃºn tipo de relaciÃ³n u orden\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "city_encoder = LabelEncoder()\n",
    "df_cat[\"city\"] = city_encoder.fit_transform(df_cat[\"city\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83db501e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(left = df_num, right = df_cat, on = \"id\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027d5b82",
   "metadata": {},
   "source": [
    "### Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13175e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"bathrooms_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e5532b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"bathrooms_text\"] = df[\"bathrooms_text\"].apply(lambda x : np.ceil(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb94570",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.columns:\n",
    "    \n",
    "    print(i)\n",
    "    sns.kdeplot(df[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d15f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"accommodates\"] <= 8]\n",
    "df = df[df[\"bathrooms_text\"].between(1, 2)]\n",
    "df = df[df[\"bedrooms\"] <= 4]\n",
    "df = df[df[\"beds\"].between(1, 5)]\n",
    "df = df[df[\"amenities\"] <= 50]\n",
    "df = df[df[\"minimum_nights\"] <= 30]\n",
    "df = df[df[\"number_of_reviews\"] <= 300]\n",
    "df = df[df[\"reviews_per_month\"] <= 8]\n",
    "df = df[df[\"price\"] <= 400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade688db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"Shared room\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad2e58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in df.columns:\n",
    "    \n",
    "#     print(i)\n",
    "#     sns.kdeplot(df[i])\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69de899",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "x_scaler = MinMaxScaler()\n",
    "df[df.drop(\"price\", axis = 1).columns] = x_scaler.fit_transform(df[df.drop(\"price\", axis = 1).columns])\n",
    "\n",
    "y_scaler = MinMaxScaler()\n",
    "df[\"price\"] = y_scaler.fit_transform(df[[\"price\"]]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e4729f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"id\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f484f357",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff135b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop([\"price\"], axis = 1)\n",
    "y = df[\"price\"]\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9140095",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "print(f\"X_train: {X_train.shape} | y_train: {y_train.shape}\")\n",
    "print(f\"X_test: {X_test.shape} | y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d6c7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelos\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# MÃ©tricas\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45d7a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "modelos = [LinearRegression(), KNeighborsRegressor(), DecisionTreeRegressor(),\n",
    "           RandomForestRegressor(), SVR(), AdaBoostRegressor(), GradientBoostingRegressor()]\n",
    "\n",
    "metricas = list() \n",
    "\n",
    "for model in modelos:\n",
    "    \n",
    "    # fit\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # predict\n",
    "    yhat = model.predict(X_test)\n",
    "    \n",
    "    # metrics\n",
    "    r2 = r2_score(y_test, yhat)\n",
    "    mse = mean_squared_error(y_test, yhat)\n",
    "    \n",
    "    metricas.append([str(model), r2, mse, model])\n",
    "    \n",
    "df_metricas = pd.DataFrame(data = metricas, columns = [\"model_name\", \"r2\", \"mse\", \"model\"])\n",
    "\n",
    "df_metricas.sort_values(by = \"r2\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a8ddf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = df_metricas[\"model\"][3]\n",
    "\n",
    "modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02bbdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = modelo.predict(X_test)\n",
    "\n",
    "for i, j in zip(yhat[:5], y_test[:5]):\n",
    "    print(f\"PredicciÃ³n:{i} \\tValor real:{j}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600df5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance btw real and predicted values\n",
    "\n",
    "plt.figure(figsize = (8, 5))\n",
    "\n",
    "sns.scatterplot(x = y_test, y = yhat, alpha = 0.5, color = \"blue\")\n",
    "\n",
    "plt.xlabel(\"Valores Reales (y_train)\", size = 18)\n",
    "plt.ylabel(\"Predicciones (yhat)\", size = 18)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919e318b",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = np.argsort(modelo.feature_importances_)[::-1]\n",
    "\n",
    "for i in importances:\n",
    "    \n",
    "    print(i, modelo.feature_importances_[i]*100, df.drop(\"price\", axis = 1).columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc6736c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_inv = y_scaler.inverse_transform([y_test]).flatten()\n",
    "yhat_inv = y_scaler.inverse_transform([yhat]).flatten()\n",
    "\n",
    "\n",
    "r2 = r2_score(y_test_inv, yhat_inv)\n",
    "mse = mean_squared_error(y_test_inv, yhat_inv)\n",
    "\n",
    "print(r2, mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d640b534",
   "metadata": {},
   "source": [
    "# GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328dcaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# # Modelo\n",
    "# model = RandomForestRegressor()\n",
    "\n",
    "# # Parametros a iterar\n",
    "# params = {\"n_estimators\" : [i for i in range(100, 1001, 50)],\n",
    "#           \"max_depth\"    : [8, 10, 12, 14, 16],\n",
    "#           \"max_features\" : [\"log2\", \"sqrt\"]}\n",
    "\n",
    "# # Metricas\n",
    "# scorers = {\"r2\", \"neg_mean_squared_error\"}\n",
    "\n",
    "# #GridSearchCV\n",
    "# grid_solver = GridSearchCV(estimator  = model, \n",
    "#                            param_grid = params, \n",
    "#                            scoring    = scorers,\n",
    "#                            cv         = 10,\n",
    "#                            refit      = \"r2\",\n",
    "#                            n_jobs     = -1, \n",
    "#                            verbose    = 2)\n",
    "\n",
    "# # Resultados\n",
    "# model_result = grid_solver.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d74bcb6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# model_result.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5d377d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_result.cv_results_[\"mean_test_r2\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ea4b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_result.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0068d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_result.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0af6d0",
   "metadata": {},
   "source": [
    "# Training the definitive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07326c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_def = df.drop([\"price\"], axis = 1)\n",
    "# y_def = df[\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d501be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = RandomForestRegressor(max_depth=16, max_features='sqrt', n_estimators=650, random_state = 42)\n",
    "# model.fit(X_def, y_def)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb598f3",
   "metadata": {},
   "source": [
    "## Downloading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a149e5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# with open(\"model_rf.sav\", \"wb\") as file:\n",
    "#     pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ade69fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f629a957",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
