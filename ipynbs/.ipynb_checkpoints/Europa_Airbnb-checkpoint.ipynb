{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14c82521",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "id": "65b808e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_madrid = pd.read_csv(\"madrid.csv\")\n",
    "df_rome = pd.read_csv(\"rome.csv\")\n",
    "df_paris = pd.read_csv(\"paris.csv\")\n",
    "df_oslo = pd.read_csv(\"oslo.csv\")\n",
    "df_london = pd.read_csv(\"london.csv\")\n",
    "df_geneva = pd.read_csv(\"geneva.csv\")\n",
    "df_dublin = pd.read_csv(\"dublin.csv\")\n",
    "df_barcelona = pd.read_csv(\"barcelona.csv\")\n",
    "df_athens = pd.read_csv(\"athens.csv\")\n",
    "df_amsterdam = pd.read_csv(\"amsterdam.csv\")\n",
    "\n",
    "\n",
    "l_dataframes = [df_madrid, df_barcelona, df_rome, df_paris, df_oslo, df_london, df_geneva, df_dublin, df_athens, df_amsterdam]"
=======
   "execution_count": 2,
   "id": "65b808e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'madrid.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22928\\2635340765.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_madrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"madrid.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# df_malaga = pd.read_csv(\"malaga.csv\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# df_euskadi = pd.read_csv(\"euskadi.csv\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# df_girona = pd.read_csv(\"girona.csv\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# df_mallorca = pd.read_csv(\"mallorca.csv\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 932\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    933\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1214\u001b[0m             \u001b[1;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[1;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[0;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 786\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'madrid.csv'"
     ]
    }
   ],
   "source": [
    "df_madrid = pd.read_csv(\"madrid.csv\")\n",
    "# df_malaga = pd.read_csv(\"malaga.csv\")\n",
    "# df_euskadi = pd.read_csv(\"euskadi.csv\")\n",
    "# df_girona = pd.read_csv(\"girona.csv\")\n",
    "# df_mallorca = pd.read_csv(\"mallorca.csv\")\n",
    "# df_menorca = pd.read_csv(\"menorca.csv\")\n",
    "# df_sevilla = pd.read_csv(\"sevilla.csv\")\n",
    "# df_valencia = pd.read_csv(\"valencia.csv\")\n",
    "df_barcelona = pd.read_csv(\"barcelona.csv\")\n",
    "\n",
    "l_dataframes = [df_madrid, df_barcelona]"
>>>>>>> 863eda73116c73b06ab16ce15d50e3bf7953ce92
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "id": "c2586823",
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 3,
   "id": "c2586823",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'l_dataframes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22928\\733531104.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0ml_dataframes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"source\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'l_dataframes' is not defined"
     ]
    }
   ],
>>>>>>> 863eda73116c73b06ab16ce15d50e3bf7953ce92
   "source": [
    "for i in l_dataframes:\n",
    "    i.drop(\"source\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fa2a4b",
<<<<<<< HEAD
   "metadata": {
    "scrolled": true
   },
=======
   "metadata": {},
>>>>>>> 863eda73116c73b06ab16ce15d50e3bf7953ce92
   "outputs": [],
   "source": [
    "df = pd.concat(l_dataframes)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109b899e",
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "l_columns_chosen = ['id', 'neighbourhood_cleansed',\n",
    "                    'room_type', 'accommodates',\n",
    "                    'bathrooms_text', 'bedrooms', 'beds', 'amenities', 'price',\n",
    "                    'minimum_nights', 'maximum_nights', 'availability_365',\n",
    "                    'number_of_reviews', 'reviews_per_month', 'host_total_listings_count']\n",
    "df = df[l_columns_chosen]"
=======
    "l_columns_chosen = ['host_total_listings_count', 'accommodates', 'bathrooms_text',\n",
    "                    'bedrooms', 'beds', 'amenities', 'minimum_nights', 'maximum_nights',\n",
    "                    'availability_365', 'number_of_reviews', 'reviews_per_month',\n",
    "                    'neighbourhood_group_cleansed', 'price', 'Entire home/apt',\n",
    "                    'Private room']"
>>>>>>> 863eda73116c73b06ab16ce15d50e3bf7953ce92
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23081a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()/df.shape[0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "47859411",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"bathrooms_text\"] = df[\"bathrooms_text\"].apply(lambda x : x.split(\" \")[0] if (type(x) == str) and (\"bath\" in x) else np.nan)\n",
    "\n",
    "bath_map = {\"Private\" : 1, \"Shared\" : 0.5, \"Half-bath\" : 0.5}\n",
    "\n",
    "df[\"bathrooms_text\"] = df[\"bathrooms_text\"].apply(lambda x : bath_map[x] if x in bath_map.keys() else float(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c60904d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# amenities: número de elementos en la lista\n",
    "\n",
    "list_amenities = list()\n",
    "\n",
    "for num, x in enumerate(df[\"amenities\"].values):\n",
    "    try:\n",
    "        list_amenities.append(len(json.loads((x.replace(\"'\", '\"')))))\n",
    "        \n",
    "    except:\n",
    "        list_amenities.append(len(x.replace(\"'\", '\"').replace(\"\\\\\", \"\")))\n",
    "        \n",
    "        \n",
    "df[\"amenities\"] = list_amenities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e76c01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import json\n",
    "from collections import Counter\n",
    "l_amenities_cleaned, l_amenities_sublisted = list(),list()\n",
    "for i in df[\"amenities\"]:\n",
    "    \n",
    "    l_amenities_sublisted.append(json.loads(i))\n",
    "    \n",
    "    for j in json.loads(i):\n",
    "    \n",
    "        l_amenities_cleaned.append(j)\n",
    "\n",
    "l_values = list(Counter(l_amenities_cleaned).values())\n",
    "l_keys = list(Counter(l_amenities_cleaned).keys())\n",
    "\n",
    "l_valuable_amenities, l_not_relevant_amenities = [], []\n",
    "\n",
    "for i in l_values:\n",
    "    \n",
    "    if i > 10000:\n",
    "        \n",
    "        l_valuable_amenities.append(l_keys[l_values.index(i)])\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        l_not_relevant_amenities.append(l_keys[l_values.index(i)])\n",
    "        \n",
    "cont = 0\n",
    "l_popular, l_exclusive = [],[]\n",
    "\n",
    "for i in l_amenities_sublisted:\n",
    "    \n",
    "    for j in l_valuable_amenities:\n",
    "        \n",
    "        if j in i:\n",
    "            \n",
    "            cont+=1\n",
    "        \n",
    "    if cont > len(i)/2:\n",
    "\n",
    "        l_popular.append(1)\n",
    "\n",
    "    else:\n",
    "\n",
    "        l_popular.append(0)\n",
    "\n",
    "    cont = 0\n",
    "        \n",
    "    for k in l_not_relevant_amenities:\n",
    "        \n",
    "        if k in i:\n",
    "            \n",
    "            cont += 1\n",
    "            \n",
    "    if cont > len(i)/2:\n",
    "\n",
    "        l_exclusive.append(1)\n",
    "\n",
    "    else:\n",
    "\n",
    "        l_exclusive.append(0)\n",
    "            \n",
    "    cont = 0\n",
    "    \n",
    "df[\"popular_amenities\"] = l_popular\n",
    "df[\"exclusive_amenities\"] = l_exclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11ef0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import json\n",
    "from collections import Counter\n",
    "l_amenities_cleaned, l_amenities_sublisted = list(),list()\n",
    "for i in df[\"amenities\"]:\n",
    "    \n",
    "    l_amenities_sublisted.append(json.loads(i))\n",
    "    \n",
    "    for j in json.loads(i):\n",
    "    \n",
    "        l_amenities_cleaned.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60eb353a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "l_values = list(Counter(l_amenities_cleaned).values())\n",
    "l_keys = list(Counter(l_amenities_cleaned).keys())\n",
    "\n",
    "l_valuable_amenities, l_not_relevant_amenities = [], []\n",
    "\n",
    "for i in l_values:\n",
    "    \n",
    "    if i > 10000:\n",
    "        \n",
    "        l_valuable_amenities.append(l_keys[l_values.index(i)])\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        l_not_relevant_amenities.append(l_keys[l_values.index(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3f3c2c",
   "metadata": {},
   "outputs": [],
=======
   "id": "3c60904d",
   "metadata": {},
   "outputs": [],
>>>>>>> 863eda73116c73b06ab16ce15d50e3bf7953ce92
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "ea7043e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont = 0\n",
    "l_popular, l_exclusive = [],[]\n",
    "\n",
    "for i in l_amenities_sublisted:\n",
    "    \n",
    "    for j in l_valuable_amenities:\n",
    "        \n",
    "        if j in i:\n",
    "            \n",
    "            cont+=1\n",
    "        \n",
    "    if cont > len(i)/2:\n",
    "\n",
    "        l_popular.append(1)\n",
    "\n",
    "    else:\n",
    "\n",
    "        l_popular.append(0)\n",
    "\n",
    "    cont = 0\n",
    "        \n",
    "    for k in l_not_relevant_amenities:\n",
    "        \n",
    "        if k in i:\n",
    "            \n",
    "            cont += 1\n",
    "            \n",
    "    if cont > len(i)/2:\n",
    "\n",
    "        l_exclusive.append(1)\n",
    "\n",
    "    else:\n",
    "\n",
    "        l_exclusive.append(0)\n",
    "            \n",
    "    cont = 0\n",
    "    \n",
    "df[\"popular_amenities\"] = l_popular\n",
    "df[\"exclusive_amenities\"] = l_exclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5adc1af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92b6d00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0676fb64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f782ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d43c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.drop(\"amenities\", axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96b934b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396ff4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"price\"] = df[\"price\"].apply(lambda x: float(x.strip(\"$\").replace(',', '')) if pd.notnull(x) else x).values"
   ]
=======
   "id": "f96b934b",
   "metadata": {},
   "outputs": [],
   "source": []
>>>>>>> 863eda73116c73b06ab16ce15d50e3bf7953ce92
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4beec4a",
   "metadata": {},
   "outputs": [],
<<<<<<< HEAD
   "source": [
    "df"
   ]
=======
   "source": []
>>>>>>> 863eda73116c73b06ab16ce15d50e3bf7953ce92
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0380f07",
   "metadata": {},
   "outputs": [],
<<<<<<< HEAD
   "source": [
    "df_num = df._get_numeric_data()"
   ]
=======
   "source": []
>>>>>>> 863eda73116c73b06ab16ce15d50e3bf7953ce92
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c51e006",
   "metadata": {},
   "outputs": [],
<<<<<<< HEAD
   "source": [
    "df_cat = df.drop(df_num.columns, axis = 1)\n",
    "df_cat = pd.concat([df_cat, df_num[[\"id\"]]], axis = 1)"
   ]
=======
   "source": []
>>>>>>> 863eda73116c73b06ab16ce15d50e3bf7953ce92
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ab4a9e",
   "metadata": {},
   "outputs": [],
<<<<<<< HEAD
   "source": [
    "# room_type: eliminar \"Hotel room\" y transformar a dummies\n",
    "\n",
    "df_cat = df_cat[df_cat[\"room_type\"] != \"Hotel room\"]\n",
    "\n",
    "df_cat = pd.concat([df_cat, pd.get_dummies(data = df_cat[\"room_type\"])], axis = 1).drop(\"room_type\", axis = 1)"
   ]
=======
   "source": []
>>>>>>> 863eda73116c73b06ab16ce15d50e3bf7953ce92
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2e3a0c",
   "metadata": {},
   "outputs": [],
<<<<<<< HEAD
   "source": [
    "# Uso el LabelEncoder para transformarlo a números sin ningún tipo de relación u orden\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "neighbourhood_encoder = LabelEncoder()\n",
    "df_cat[\"neighbourhood_cleansed\"] = neighbourhood_encoder.fit_transform(df_cat[\"neighbourhood_cleansed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9623125a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uso el LabelEncoder para transformarlo a números sin ningún tipo de relación u orden\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "city_encoder = LabelEncoder()\n",
    "df_cat[\"city\"] = city_encoder.fit_transform(df_cat[\"city\"])"
   ]
=======
   "source": []
>>>>>>> 863eda73116c73b06ab16ce15d50e3bf7953ce92
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83db501e",
   "metadata": {},
   "outputs": [],
<<<<<<< HEAD
   "source": [
    "df = pd.merge(left = df_num, right = df_cat, on = \"id\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027d5b82",
   "metadata": {},
   "source": [
    "### Outliers"
   ]
=======
   "source": []
>>>>>>> 863eda73116c73b06ab16ce15d50e3bf7953ce92
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "13175e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"bathrooms_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e5532b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"bathrooms_text\"] = df[\"bathrooms_text\"].apply(lambda x : np.ceil(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb94570",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.columns:\n",
    "    \n",
    "    print(i)\n",
    "    sns.kdeplot(df[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d15f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"accommodates\"] <= 8]\n",
    "df = df[df[\"bathrooms_text\"].between(1, 2)]\n",
    "df = df[df[\"bedrooms\"] <= 4]\n",
    "df = df[df[\"beds\"].between(1, 5)]\n",
    "df = df[df[\"amenities\"] <= 50]\n",
    "df = df[df[\"minimum_nights\"] <= 30]\n",
    "df = df[df[\"number_of_reviews\"] <= 300]\n",
    "df = df[df[\"reviews_per_month\"] <= 8]\n",
    "df = df[df[\"price\"] <= 400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade688db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"Shared room\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad2e58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in df.columns:\n",
    "    \n",
    "#     print(i)\n",
    "#     sns.kdeplot(df[i])\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69de899",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "x_scaler = MinMaxScaler()\n",
    "df[df.drop(\"price\", axis = 1).columns] = x_scaler.fit_transform(df[df.drop(\"price\", axis = 1).columns])\n",
    "\n",
    "y_scaler = MinMaxScaler()\n",
    "df[\"price\"] = y_scaler.fit_transform(df[[\"price\"]]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e4729f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"id\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f484f357",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff135b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop([\"price\"], axis = 1)\n",
    "y = df[\"price\"]\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9140095",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "print(f\"X_train: {X_train.shape} | y_train: {y_train.shape}\")\n",
    "print(f\"X_test: {X_test.shape} | y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d6c7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelos\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Métricas\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45d7a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "modelos = [LinearRegression(), KNeighborsRegressor(), DecisionTreeRegressor(),\n",
    "           RandomForestRegressor(), SVR(), AdaBoostRegressor(), GradientBoostingRegressor()]\n",
    "\n",
    "metricas = list() \n",
    "\n",
    "for model in modelos:\n",
    "    \n",
    "    # fit\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # predict\n",
    "    yhat = model.predict(X_test)\n",
    "    \n",
    "    # metrics\n",
    "    r2 = r2_score(y_test, yhat)\n",
    "    mse = mean_squared_error(y_test, yhat)\n",
    "    \n",
    "    metricas.append([str(model), r2, mse, model])\n",
    "    \n",
    "df_metricas = pd.DataFrame(data = metricas, columns = [\"model_name\", \"r2\", \"mse\", \"model\"])\n",
    "\n",
    "df_metricas.sort_values(by = \"r2\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a8ddf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = df_metricas[\"model\"][3]\n",
    "\n",
    "modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02bbdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = modelo.predict(X_test)\n",
    "\n",
    "for i, j in zip(yhat[:5], y_test[:5]):\n",
    "    print(f\"Predicción:{i} \\tValor real:{j}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600df5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance btw real and predicted values\n",
    "\n",
    "plt.figure(figsize = (8, 5))\n",
    "\n",
    "sns.scatterplot(x = y_test, y = yhat, alpha = 0.5, color = \"blue\")\n",
    "\n",
    "plt.xlabel(\"Valores Reales (y_train)\", size = 18)\n",
    "plt.ylabel(\"Predicciones (yhat)\", size = 18)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919e318b",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = np.argsort(modelo.feature_importances_)[::-1]\n",
    "\n",
    "for i in importances:\n",
    "    \n",
    "    print(i, modelo.feature_importances_[i]*100, df.drop(\"price\", axis = 1).columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc6736c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_inv = y_scaler.inverse_transform([y_test]).flatten()\n",
    "yhat_inv = y_scaler.inverse_transform([yhat]).flatten()\n",
    "\n",
    "\n",
    "r2 = r2_score(y_test_inv, yhat_inv)\n",
    "mse = mean_squared_error(y_test_inv, yhat_inv)\n",
    "\n",
    "print(r2, mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d640b534",
   "metadata": {},
   "source": [
    "# GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328dcaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# # Modelo\n",
    "# model = RandomForestRegressor()\n",
    "\n",
    "# # Parametros a iterar\n",
    "# params = {\"n_estimators\" : [i for i in range(100, 1001, 50)],\n",
    "#           \"max_depth\"    : [8, 10, 12, 14, 16],\n",
    "#           \"max_features\" : [\"log2\", \"sqrt\"]}\n",
    "\n",
    "# # Metricas\n",
    "# scorers = {\"r2\", \"neg_mean_squared_error\"}\n",
    "\n",
    "# #GridSearchCV\n",
    "# grid_solver = GridSearchCV(estimator  = model, \n",
    "#                            param_grid = params, \n",
    "#                            scoring    = scorers,\n",
    "#                            cv         = 10,\n",
    "#                            refit      = \"r2\",\n",
    "#                            n_jobs     = -1, \n",
    "#                            verbose    = 2)\n",
    "\n",
    "# # Resultados\n",
    "# model_result = grid_solver.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d74bcb6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# model_result.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5d377d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_result.cv_results_[\"mean_test_r2\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ea4b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_result.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0068d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_result.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0af6d0",
   "metadata": {},
   "source": [
    "# Training the definitive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07326c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_def = df.drop([\"price\"], axis = 1)\n",
    "# y_def = df[\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d501be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = RandomForestRegressor(max_depth=16, max_features='sqrt', n_estimators=650, random_state = 42)\n",
    "# model.fit(X_def, y_def)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb598f3",
   "metadata": {},
   "source": [
    "## Downloading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a149e5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# with open(\"model_rf.sav\", \"wb\") as file:\n",
    "#     pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ade69fe",
=======
   "id": "077ebcd1",
>>>>>>> 863eda73116c73b06ab16ce15d50e3bf7953ce92
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "f629a957",
=======
   "id": "38e5532b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d15f32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade688db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012d468c",
>>>>>>> 863eda73116c73b06ab16ce15d50e3bf7953ce92
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
